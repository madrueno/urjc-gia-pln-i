{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Tema 2: Análisis textual con NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "063gulcubq5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH_DATA = Path.cwd().parent / 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio1",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "Tokenizar un texto en inglés utilizando NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ejercicio1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'US', 'Open', 'will', 'become', 'a', '15-day', 'tournament', 'in', '2025', ',', 'beginning', 'on', 'a', 'weekend', 'for', 'the', 'first', 'time', 'in', 'the', 'Open', 'era', '.']\n",
      "['This', 'year', \"'s\", 'main', 'draw', 'at', 'Flushing', 'Meadows', 'will', 'start', 'on', 'Sunday', ',', '24', 'August', 'and', 'end', 'on', 'Sunday', ',', '7', 'September', '.']\n",
      "['It', 'becomes', 'the', 'latest', 'Grand', 'Slam', 'to', 'announce', 'a', 'Sunday', 'start', '.']\n",
      "['The', 'Australian', 'Open', 'expanded', 'to', 'a', '15-day', 'tournament', 'in', '2024', ',', 'after', 'the', 'French', 'Open', 'took', 'that', 'decision', 'in', '2006', '.']\n",
      "['That', 'leaves', 'Wimbledon', 'as', 'the', 'only', 'remaining', 'Slam', 'event', 'to', 'retain', 'the', 'traditional', 'Monday', 'start', '.']\n",
      "['In', 'making', 'the', 'change', ',', 'the', 'US', 'Open', 'said', 'the', 'move', 'would', 'allow', '``', 'more', 'fan', 'access', 'than', 'ever', 'to', 'the', 'main', 'draw', 'following', 'three', 'consecutive', 'years', 'of', 'record-breaking', 'attendance', \"''\", '.']\n",
      "['The', 'tournament', 'estimates', 'the', 'expansion', 'will', 'allow', 'access', 'for', 'an', 'additional', '70,000', 'spectators', '.']\n",
      "['Men', \"'s\", 'and', 'women', \"'s\", 'singles', 'first-round', 'matches', 'will', 'be', 'played', 'across', 'the', 'opening', 'three', 'days', 'in', 'New', 'York', ',', 'from', 'Sunday', 'to', 'Tuesday', '.']\n",
      "['The', 'Australian', 'Open', 'took', 'the', 'decision', 'to', 'become', 'a', '15-day', 'event', 'in', 'an', 'attempt', 'to', 'reduce', 'the', 'number', 'of', 'late-night', 'finishes', 'at', 'Melbourne', 'Park', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "text = \"\"\"The US Open will become a 15-day tournament in 2025, beginning on a weekend for the first time in the Open era. This year's main draw at Flushing Meadows will start on Sunday, 24 August and end on Sunday, 7 September. It becomes the latest Grand Slam to announce a Sunday start. The Australian Open expanded to a 15-day tournament in 2024, after the French Open took that decision in 2006. That leaves Wimbledon as the only remaining Slam event to retain the traditional Monday start. In making the change, the US Open said the move would allow \"more fan access than ever to the main draw following three consecutive years of record-breaking attendance\". The tournament estimates the expansion will allow access for an additional 70,000 spectators. Men's and women's singles first-round matches will be played across the opening three days in New York, from Sunday to Tuesday. The Australian Open took the decision to become a 15-day event in an attempt to reduce the number of late-night finishes at Melbourne Park.\"\"\"\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "sentence_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "for sentence in sentence_tokens:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio1_v2",
   "metadata": {},
   "source": [
    "### Versión alternativa con sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ejercicio1_v2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'US', 'Open', 'will', 'become', 'a', '15-day', 'tournament', 'in', '2025', ',', 'beginning', 'on', 'a', 'weekend', 'for', 'the', 'first', 'time', 'in', 'the', 'Open', 'era', '.']\n",
      "['This', 'year', \"'s\", 'main', 'draw', 'at', 'Flushing', 'Meadows', 'will', 'start', 'on', 'Sunday', ',', '24', 'August', 'and', 'end', 'on', 'Sunday', ',', '7', 'September', '.']\n",
      "['It', 'becomes', 'the', 'latest', 'Grand', 'Slam', 'to', 'announce', 'a', 'Sunday', 'start', '.']\n",
      "['The', 'Australian', 'Open', 'expanded', 'to', 'a', '15-day', 'tournament', 'in', '2024', ',', 'after', 'the', 'French', 'Open', 'took', 'that', 'decision', 'in', '2006', '.']\n",
      "['That', 'leaves', 'Wimbledon', 'as', 'the', 'only', 'remaining', 'Slam', 'event', 'to', 'retain', 'the', 'traditional', 'Monday', 'start', '.']\n",
      "['In', 'making', 'the', 'change', ',', 'the', 'US', 'Open', 'said', 'the', 'move', 'would', 'allow', '``', 'more', 'fan', 'access', 'than', 'ever', 'to', 'the', 'main', 'draw', 'following', 'three', 'consecutive', 'years', 'of', 'record-breaking', 'attendance', \"''\", '.']\n",
      "['The', 'tournament', 'estimates', 'the', 'expansion', 'will', 'allow', 'access', 'for', 'an', 'additional', '70,000', 'spectators', '.']\n",
      "['Men', \"'s\", 'and', 'women', \"'s\", 'singles', 'first-round', 'matches', 'will', 'be', 'played', 'across', 'the', 'opening', 'three', 'days', 'in', 'New', 'York', ',', 'from', 'Sunday', 'to', 'Tuesday', '.']\n",
      "['The', 'Australian', 'Open', 'took', 'the', 'decision', 'to', 'become', 'a', '15-day', 'event', 'in', 'an', 'attempt', 'to', 'reduce', 'the', 'number', 'of', 'late-night', 'finishes', 'at', 'Melbourne', 'Park', '.']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio2",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "Tokenizar un texto en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ejercicio2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El', 'campus', 'de', 'Fuenlabrada', 'acoge', 'el', 'próximo', 'jueves', '30', 'de', 'enero', 'este', 'evento', ',', 'coincidiendo', 'con', 'el', 'Día', 'Internacional', 'de', 'la', 'No', 'Violencia', 'y', 'la', 'Paz', '.']\n",
      "['Su', 'objetivo', 'es', 'poner', 'de', 'manifiesto', 'la', 'importancia', 'de', 'la', 'implicación', 'institucional', 'y', 'académica', 'para', 'erradicar', 'el', 'abuso', 'sexual', 'infantil', ',', 'destacando', 'el', 'rol', 'de', 'la', 'educación', 'y', 'la', 'sensibilización', 'social', 'como', 'herramientas', 'fundamentales', '.']\n",
      "['La', 'jornada', 'contará', 'con', 'especialistas', 'referentes', 'en', 'abuso', 'sexual', 'infantil', 'como', 'Noemí', 'Pereda', ',', 'de', 'la', 'Universidad', 'de', 'Barcelona', ';', 'Lluis', 'Ballester', ',', 'de', 'la', 'Universidad', 'de', 'las', 'Islas', 'Baleares', ';', 'Vladimir', 'Essau', ',', 'de', 'la', 'Universidad', 'de', 'Valencia', ',', 'y', 'Macarena', 'Céspedes', ',', 'directora', 'Global', 'de', 'Incidencia', 'e', 'Investigación', 'en', 'ONG', 'Educo', '.']\n",
      "['Además', ',', 'alumnado', 'de', 'entre', '15', 'y', '18', 'años', 'de', 'institutos', 'y', 'universidades', 'acudirán', 'al', 'evento', 'para', 'aportar', 'sus', 'voces', 'con', 'el', 'objetivo', 'de', 'abordar', 'esta', 'lacra', 'social', 'desde', 'diferentes', 'perspectivas', '.']\n"
     ]
    }
   ],
   "source": [
    "text_es = \"\"\"El campus de Fuenlabrada acoge el próximo jueves 30 de enero este evento, coincidiendo con el Día Internacional de la No Violencia y la Paz. Su objetivo es poner de manifiesto la importancia de la implicación institucional y académica para erradicar el abuso sexual infantil, destacando el rol de la educación y la sensibilización social como herramientas fundamentales. La jornada contará con especialistas referentes en abuso sexual infantil como Noemí Pereda, de la Universidad de Barcelona; Lluis Ballester, de la Universidad de las Islas Baleares; Vladimir Essau, de la Universidad de Valencia, y Macarena Céspedes, directora Global de Incidencia e Investigación en ONG Educo. Además, alumnado de entre 15 y 18 años de institutos y universidades acudirán al evento para aportar sus voces con el objetivo de abordar esta lacra social desde diferentes perspectivas.\"\"\"\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer(\"spanish\")\n",
    "sentence_tokens = tokenizer.tokenize(text_es)\n",
    "\n",
    "for sentence in sentence_tokens:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio3",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Comparar tokenización con `split()` vs `word_tokenize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ejercicio3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con split(): ['Hola,', '¿cómo', 'estás?']\n",
      "Con word_tokenize(): ['Hola', ',', '¿cómo', 'estás', '?']\n"
     ]
    }
   ],
   "source": [
    "texto = \"Hola, ¿cómo estás?\"\n",
    "\n",
    "# split(): método básico de Python\n",
    "# No maneja adecuadamente la puntuación, contracciones o caracteres especiales\n",
    "palabras_split = texto.split()\n",
    "print(\"Con split():\", palabras_split)\n",
    "\n",
    "# word_tokenize(): tokenización avanzada de NLTK\n",
    "# Maneja puntuación, contracciones y aspectos del lenguaje natural\n",
    "palabras_nltk = word_tokenize(texto)\n",
    "print(\"Con word_tokenize():\", palabras_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio4",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "Eliminar signos de puntuación de un texto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ejercicio4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: ['Data', 'science', 'is', 'the', 'study', 'of', 'the', 'extraction', 'of', 'knowledge', 'from', 'data', '.']\n",
      "Después: ['Data', 'science', 'is', 'the', 'study', 'of', 'the', 'extraction', 'of', 'knowledge', 'from', 'data']\n",
      "\n",
      "Antes: ['It', 'uses', 'various', 'techniques', 'from', 'many', 'fields', ',', 'including', 'signal', 'processing', ',', 'mathematics', ',', 'probability', 'models', ',', 'machine', 'learning', ',', 'computer', 'programming', ',', 'statistics', ',', 'data', 'engineering', ',', 'pattern', 'recognition', 'and', 'learning', ',', 'visualization', ',', 'uncertainty', 'modeling', ',', 'data', 'warehousing', ',', 'and', 'high', 'performance', 'computing', 'with', 'the', 'goal', 'of', 'extracting', 'useful', 'knowledge', 'from', 'the', 'data', '.']\n",
      "Después: ['It', 'uses', 'various', 'techniques', 'from', 'many', 'fields', 'including', 'signal', 'processing', 'mathematics', 'probability', 'models', 'machine', 'learning', 'computer', 'programming', 'statistics', 'data', 'engineering', 'pattern', 'recognition', 'and', 'learning', 'visualization', 'uncertainty', 'modeling', 'data', 'warehousing', 'and', 'high', 'performance', 'computing', 'with', 'the', 'goal', 'of', 'extracting', 'useful', 'knowledge', 'from', 'the', 'data']\n",
      "\n",
      "Antes: ['Data', 'Science', 'is', 'not', 'restricted', 'to', 'only', 'big', 'data', ',', 'although', 'the', 'fact', 'that', 'data', 'is', 'scaling', 'up', 'makes', 'big', 'data', 'an', 'important', 'aspect', 'of', 'data', 'science', '.']\n",
      "Después: ['Data', 'Science', 'is', 'not', 'restricted', 'to', 'only', 'big', 'data', 'although', 'the', 'fact', 'that', 'data', 'is', 'scaling', 'up', 'makes', 'big', 'data', 'an', 'important', 'aspect', 'of', 'data', 'science']\n",
      "\n",
      "Antes: ['A', 'practitioner', 'of', 'data', 'science', 'is', 'called', 'a', 'data', 'scientist', '.']\n",
      "Después: ['A', 'practitioner', 'of', 'data', 'science', 'is', 'called', 'a', 'data', 'scientist']\n",
      "\n",
      "Antes: ['Data', 'scientists', 'solve', 'complex', 'data', 'problems', 'using', 'various', 'elements', 'of', 'mathematics', ',', 'statistics', 'and', 'computer', 'science', ',', 'although', 'expertise', 'in', 'these', 'subjects', 'are', 'not', 'required', '.']\n",
      "Después: ['Data', 'scientists', 'solve', 'complex', 'data', 'problems', 'using', 'various', 'elements', 'of', 'mathematics', 'statistics', 'and', 'computer', 'science', 'although', 'expertise', 'in', 'these', 'subjects', 'are', 'not', 'required']\n",
      "\n",
      "Antes: ['However', ',', 'a', 'data', 'scientist', 'is', 'most', 'likely', 'to', 'be', 'an', 'expert', 'in', 'only', 'one', 'or', 'two', 'of', 'these', 'disciplines', ',', 'meaning', 'that', 'cross', 'disciplinary', 'teams', 'can', 'be', 'a', 'key', 'component', 'of', 'data', 'science', '.']\n",
      "Después: ['However', 'a', 'data', 'scientist', 'is', 'most', 'likely', 'to', 'be', 'an', 'expert', 'in', 'only', 'one', 'or', 'two', 'of', 'these', 'disciplines', 'meaning', 'that', 'cross', 'disciplinary', 'teams', 'can', 'be', 'a', 'key', 'component', 'of', 'data', 'science']\n",
      "\n",
      "Antes: ['Good', 'data', 'scientists', 'are', 'able', 'to', 'apply', 'their', 'skills', 'to', 'achieve', 'a', 'broad', 'spectrum', 'of', 'end', 'results', '.']\n",
      "Después: ['Good', 'data', 'scientists', 'are', 'able', 'to', 'apply', 'their', 'skills', 'to', 'achieve', 'a', 'broad', 'spectrum', 'of', 'end', 'results']\n",
      "\n",
      "Antes: ['The', 'skill-sets', 'and', 'competencies', 'that', 'data', 'scientists', 'employ', 'vary', 'widely', '.']\n",
      "Después: ['The', 'skillsets', 'and', 'competencies', 'that', 'data', 'scientists', 'employ', 'vary', 'widely']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "sentences = nltk.tokenize.sent_tokenize(sample)\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    no_punctuation = []\n",
    "    for token in tokens:\n",
    "        punct_removed = ''.join([letter for letter in token if letter not in string.punctuation])\n",
    "        if punct_removed != '':\n",
    "            no_punctuation.append(punct_removed)\n",
    "    print(\"Antes:\", tokens)\n",
    "    print(\"Después:\", no_punctuation)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio5",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "Obtener las 5 palabras más frecuentes del texto, antes y después de eliminar puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ejercicio5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes (sin filtrar):\n",
      "[('data', 18), (',', 17), ('of', 9), ('.', 8), ('science', 6)]\n",
      "\n",
      "Palabras más frecuentes (filtradas):\n",
      "[('data', 18), ('science', 6), ('scientists', 3), ('knowledge', 2), ('various', 2)]\n",
      "\n",
      "La palabra 'data' aparece 18 veces\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "sample = sample.lower()\n",
    "tokens = nltk.word_tokenize(sample)\n",
    "\n",
    "# Sin filtrado\n",
    "frequencies = FreqDist(tokens)\n",
    "print(\"Palabras más frecuentes (sin filtrar):\")\n",
    "print(frequencies.most_common(5))\n",
    "\n",
    "# Con filtrado de puntuación y stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "filter_tokens = [token for token in tokens if token not in string.punctuation and token not in stop]\n",
    "\n",
    "frequencies = FreqDist(filter_tokens)\n",
    "print(\"\\nPalabras más frecuentes (filtradas):\")\n",
    "print(frequencies.most_common(5))\n",
    "\n",
    "print(\"\\nLa palabra 'data' aparece\", sample.count(\"data\"), \"veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio6",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "Eliminar stop words de un texto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ejercicio6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frases originales:\n",
      "['Data science is the study of the extraction of knowledge from data.', 'It uses various techniques from many fields, including signal processing, mathematics, probability models, machine learning, computer programming, statistics, data engineering, pattern recognition and learning, visualization, uncertainty modeling, data warehousing, and high performance computing with the goal of extracting useful knowledge from the data.', 'Data Science is not restricted to only big data, although the fact that data is scaling up makes big data an important aspect of data science.', 'A practitioner of data science is called a data scientist.', 'Data scientists solve complex data problems using various elements of mathematics, statistics and computer science, although expertise in these subjects are not required.', 'However, a data scientist is most likely to be an expert in only one or two of these disciplines, meaning that cross disciplinary teams can be a key component of data science.', 'Good data scientists are able to apply their skills to achieve a broad spectrum of end results.', 'The skill-sets and competencies that data scientists employ vary widely.']\n",
      "\n",
      "Stop words en inglés:\n",
      "['they', 'just', 'is', 'am', 'my', 'or', \"she'll\", 'so', 'from', 'myself', \"i'll\", 'ourselves', 'doing', \"you've\", 'been', 'o', 'this', 'because', 'than', \"isn't\", \"won't\", 'an', 'be', 'not', 'that', 'against', 'more', 'does', 'd', 'have', 'over', 'mightn', 'most', \"we'll\", 'did', \"it'd\", \"it's\", 'had', 'her', 'of', 'has', 'can', \"i'd\", 'those', 'while', 'he', \"shan't\", 'shan', \"i've\", \"i'm\", 'to', 'once', 'same', 'weren', 'needn', \"she'd\", 're', \"wouldn't\", 'yours', \"weren't\", 'nor', 'itself', 'she', 'very', \"he's\", 'about', 'after', 'shouldn', 'out', \"he'd\", 'being', 'during', 'i', 'above', 'at', 'ma', 'will', \"wasn't\", 'aren', 'each', \"they're\", 'what', 'which', 'until', \"should've\", 'his', \"we'd\", 'any', 'do', 'other', 'isn', 'theirs', 'such', 'on', 'having', 'how', 'only', 'why', 'the', 'him', 'as', \"that'll\", \"mustn't\", \"you'll\", 'was', 'its', \"we've\", \"they'd\", \"don't\", 'wouldn', 'me', 'm', \"they've\", 'too', 'no', 'y', 'himself', 'when', \"shouldn't\", 'in', \"didn't\", \"it'll\", 'whom', 'between', 'where', 'and', 'who', 'further', 'herself', 'didn', 've', 'below', 'both', 'now', 'hasn', \"couldn't\", 'under', 'again', 'there', 'if', 'all', \"you'd\", \"he'll\", 'haven', 'own', 'these', 'by', 'were', 'ain', 'you', 'ours', 'down', 'here', 'a', 'themselves', 'our', 'your', 'it', \"hasn't\", \"doesn't\", 'for', \"they'll\", \"mightn't\", \"you're\", 'some', 'won', 'doesn', 'don', 'll', 'but', 'their', \"hadn't\", \"haven't\", 'wasn', 'through', 'yourself', \"we're\", 'we', 'them', 'into', 'up', 'with', 'couldn', 's', 'then', 'off', 'should', 'are', \"she's\", \"aren't\", 'before', 'few', 'hadn', 't', 'hers', 'yourselves', \"needn't\", 'mustn']\n",
      "\n",
      "Frases sin stop words:\n",
      "data science study extraction knowledge data.\n",
      "uses various techniques many fields, including signal processing, mathematics, probability models, machine learning, computer programming, statistics, data engineering, pattern recognition learning, visualization, uncertainty modeling, data warehousing, high performance computing goal extracting useful knowledge data.\n",
      "data science restricted big data, although fact data scaling makes big data important aspect data science.\n",
      "practitioner data science called data scientist.\n",
      "data scientists solve complex data problems using various elements mathematics, statistics computer science, although expertise subjects required.\n",
      "however, data scientist likely expert one two disciplines, meaning cross disciplinary teams key component data science.\n",
      "good data scientists able apply skills achieve broad spectrum end results.\n",
      "skill-sets competencies data scientists employ vary widely.\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "sentences = nltk.sent_tokenize(sample)\n",
    "print(\"Frases originales:\")\n",
    "print(sentences)\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "print(\"\\nStop words en inglés:\")\n",
    "print(list(stop))\n",
    "\n",
    "print(\"\\nFrases sin stop words:\")\n",
    "for sentence in sentences:\n",
    "    non_stop_sentence = \" \".join([word for word in sentence.lower().split() if word not in stop])\n",
    "    print(non_stop_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio7",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "Eliminar stop words de un texto en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ejercicio7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frases originales:\n",
      "['Las personas que se dedican a la ciencia de datos se les conoce como científico de datos, de acuerdo con el proyecto Master in Data Science define al científico de datos como una mezcla de estadísticos, computólogos y pensadores creativos, con las siguientes habilidades:\\n\\nRecopilar, procesar y extraer valor de las diversas y extensas bases de datos.', 'Imaginación para comprender, visualizar y comunicar sus conclusiones a los no científicos de datos.', 'Capacidad para crear soluciones basadas en datos que aumentan los beneficios, reducen los costos.', 'Los científicos de datos trabajan en todas las industrias y hacen frente a los grandes proyectos de datos en todos los niveles.', 'El doctor en estadística Nathan Yau, precisó lo siguiente: el científico de datos es un estadístico que debería aprender interfaces de programación de aplicaciones (APIs), bases de datos y extracción de datos; es un diseñador que deberá aprender a programar; y es un computólogo que deberá saber analizar y encontrar datos con significado.', '6\\n\\nEn la tesis doctoral de Benjamin Fry explicó que el proceso para comprender mejor a los datos comenzaba con una serie de números y el objetivo de responder preguntas sobre los datos, en cada fase del proceso que él propone (adquirir, analizar, filtrar, extraer, representar, refinar e interactuar), se requiere de diferentes enfoques especializados que aporten a una mejor comprensión de los datos.', 'Entre los enfoques que menciona Fry están: ingenieros en sistemas, matemáticos, estadísticos, diseñadores gráficos, especialistas en visualización de la información y especialistas en interacciones hombre-máquina, mejor conocidos por sus siglas en inglés “HCI” (Human-Computer Interaction).', 'Además, Fry afirmó que contar con diferentes enfoques especializados lejos de resolver el problema de entendimiento de datos, se convierte en parte del problema, ya que cada especialización conduce de manera aislada el problema y el camino hacia la solución se puede perder algo en cada transición del proceso.', '7\\n\\nen:Drew Conway en su página web explica con la ayuda de un diagrama de Venn, las principales habilidades que le dan vida y forma a la ciencia de datos, así como sus relaciones de conjuntos.']\n",
      "\n",
      "Stop words en español:\n",
      "['habrá', 'hayan', 'durante', 'mis', 'teníamos', 'erais', 'tendrías', 'teniendo', 'sois', 'él', 'tendrás', 'estuviese', 'hayas', 'sea', 'estaríais', 'tenéis', 'hubiesen', 'somos', 'eso', 'otro', 'habiendo', 'habréis', 'habida', 'mucho', 'esté', 'míos', 'uno', 'tanto', 'habidos', 'con', 'tendréis', 'esa', 'habidas', 'estadas', 'estarías', 'hubiste', 'tuyos', 'hubimos', 'tendrá', 'vuestra', 'una', 'habías', 'estéis', 'tiene', 'de', 'la', 'otras', 'estabais', 'y', 'no', 'esta', 'ya', 'mi', 'nuestras', 'suya', 'estaréis', 'seríamos', 'hubiera', 'estuvieran', 'suyas', 'teníais', 'serían', 'que', 'estemos', 'seríais', 'sí', 'hube', 'ella', 'estuviesen', 'tengamos', 'otra', 'algunos', 'poco', 'más', 'tendríamos', 'sentida', 'tengan', 'estás', 'al', 'tengas', 'estar', 'hubieseis', 'seáis', 'nuestra', 'éramos', 'tuviésemos', 'hubieran', 'eras', 'suyos', 'tenida', 'habrías', 'hubieses', 'habría', 'tenga', 'estados', 'hubo', 'ellas', 'estuve', 'has', 'como', 'los', 'ti', 'estaré', 'suyo', 'tienen', 'hubierais', 'todo', 'estado', 'qué', 'estoy', 'hubieras', 'algunas', 'yo', 'tuviéramos', 'tienes', 'estada', 'las', 'tenidas', 'fueras', 'me', 'otros', 'sus', 'cual', 'tenidos', 'mía', 'habéis', 'por', 'estarán', 'estuvisteis', 'habremos', 'nuestros', 'mías', 'le', 'este', 'nuestro', 'tendríais', 'tuviesen', 'serán', 'fueseis', 'todos', 'tendremos', 'a', 'seréis', 'te', 'estuvierais', 'mío', 'estando', 'habido', 'tuyo', 'estuviste', 'ante', 'estaría', 'donde', 'algo', 'estuvieseis', 'sean', 'e', 'estará', 'tenía', 'tuvieseis', 'eran', 'tened', 'sin', 'ese', 'habíamos', 'o', 'fue', 'también', 'era', 'han', 'tuviste', 'tuvieras', 'tuvierais', 'habían', 'un', 'estuvieron', 'del', 'tendrían', 'soy', 'tuve', 'pero', 'estuvimos', 'hayáis', 'fueron', 'siente', 'habríamos', 'ellos', 'tuvieron', 'sentidas', 'cuando', 'tus', 'tu', 'en', 'había', 'estaríamos', 'seas', 'sobre', 'esos', 'se', 'nada', 'tuyas', 'tuviese', 'ha', 'nosotros', 'tendrán', 'tengáis', 'os', 'tuvieses', 'estabas', 'fui', 'mí', 'tendría', 'fueses', 'seremos', 'lo', 'tengo', 'fuese', 'estuvo', 'será', 'hasta', 'habríais', 'estamos', 'el', 'ni', 'fuimos', 'vuestros', 'habrás', 'habrían', 'entre', 'habíais', 'hubieron', 'fuésemos', 'estén', 'tuya', 'contra', 'está', 'muy', 'hemos', 'quien', 'muchos', 'estés', 'estarían', 'desde', 'estuvieses', 'hubiéramos', 'estarás', 'he', 'vuestro', 'están', 'vuestras', 'vosotros', 'hubiese', 'tuviera', 'estuviésemos', 'tenías', 'fueran', 'sentidos', 'estad', 'sentid', 'habrán', 'son', 'sintiendo', 'tenemos', 'tuvimos', 'porque', 'habré', 'tuvieran', 'quienes', 'es', 'estas', 'nosotras', 'sentido', 'hay', 'sería', 'tenían', 'fuisteis', 'tuvo', 'estuviera', 'estos', 'fuera', 'hubiésemos', 'fuéramos', 'estáis', 'haya', 'estaban', 'tenido', 'estábamos', 'para', 'fuerais', 'unos', 'su', 'fuesen', 'antes', 'les', 'seré', 'tendré', 'estaba', 'eres', 'estuviéramos', 'esto', 'hubisteis', 'tuvisteis', 'fuiste', 'serás', 'estaremos', 'nos', 'tú', 'seamos', 'estuvieras', 'hayamos', 'serías', 'vosotras', 'esas']\n",
      "\n",
      "Frases sin stop words:\n",
      "personas dedican ciencia datos conoce científico datos, acuerdo proyecto master in data science define científico datos mezcla estadísticos, computólogos pensadores creativos, siguientes habilidades: recopilar, procesar extraer valor diversas extensas bases datos.\n",
      "imaginación comprender, visualizar comunicar conclusiones científicos datos.\n",
      "capacidad crear soluciones basadas datos aumentan beneficios, reducen costos.\n",
      "científicos datos trabajan todas industrias hacen frente grandes proyectos datos niveles.\n",
      "doctor estadística nathan yau, precisó siguiente: científico datos estadístico debería aprender interfaces programación aplicaciones (apis), bases datos extracción datos; diseñador deberá aprender programar; computólogo deberá saber analizar encontrar datos significado.\n",
      "6 tesis doctoral benjamin fry explicó proceso comprender mejor datos comenzaba serie números objetivo responder preguntas datos, cada fase proceso propone (adquirir, analizar, filtrar, extraer, representar, refinar interactuar), requiere diferentes enfoques especializados aporten mejor comprensión datos.\n",
      "enfoques menciona fry están: ingenieros sistemas, matemáticos, estadísticos, diseñadores gráficos, especialistas visualización información especialistas interacciones hombre-máquina, mejor conocidos siglas inglés “hci” (human-computer interaction).\n",
      "además, fry afirmó contar diferentes enfoques especializados lejos resolver problema entendimiento datos, convierte parte problema, cada especialización conduce manera aislada problema camino hacia solución puede perder cada transición proceso.\n",
      "7 en:drew conway página web explica ayuda diagrama venn, principales habilidades dan vida forma ciencia datos, así relaciones conjuntos.\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_DATA / 'Ciencia_de_datos.txt', 'r', encoding=\"utf8\") as f:\n",
    "    spanish_sample = f.read()\n",
    "\n",
    "spanish_tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')\n",
    "sentences = spanish_tokenizer.tokenize(spanish_sample)\n",
    "print(\"Frases originales:\")\n",
    "print(sentences)\n",
    "\n",
    "stop = set(stopwords.words('spanish'))\n",
    "print(\"\\nStop words en español:\")\n",
    "print(list(stop))\n",
    "\n",
    "print(\"\\nFrases sin stop words:\")\n",
    "for sentence in sentences:\n",
    "    non_stop_sentence = \" \".join([word for word in sentence.lower().split() if word not in stop])\n",
    "    print(non_stop_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio8",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "Usar expresiones regulares para encontrar palabras con patrones específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ejercicio8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras del texto:\n",
      "['Data', 'science', 'is', 'the', 'study', 'of', 'the', 'extraction', 'of', 'knowledge', 'from', 'data', '.', 'It', 'uses', 'various', 'techniques', 'from', 'many', 'fields', ',', 'including', 'signal', 'processing', ',', 'mathematics', ',', 'probability', 'models', ',', 'machine', 'learning', ',', 'computer', 'programming', ',', 'statistics', ',', 'data', 'engineering', ',', 'pattern', 'recognition', 'and', 'learning', ',', 'visualization', ',', 'uncertainty', 'modeling', ',', 'data', 'warehousing', ',', 'and', 'high', 'performance', 'computing', 'with', 'the', 'goal', 'of', 'extracting', 'useful', 'knowledge', 'from', 'the', 'data', '.', 'Data', 'Science', 'is', 'not', 'restricted', 'to', 'only', 'big', 'data', ',', 'although', 'the', 'fact', 'that', 'data', 'is', 'scaling', 'up', 'makes', 'big', 'data', 'an', 'important', 'aspect', 'of', 'data', 'science', '.', 'A', 'practitioner', 'of', 'data', 'science', 'is', 'called', 'a', 'data', 'scientist', '.', 'Data', 'scientists', 'solve', 'complex', 'data', 'problems', 'using', 'various', 'elements', 'of', 'mathematics', ',', 'statistics', 'and', 'computer', 'science', ',', 'although', 'expertise', 'in', 'these', 'subjects', 'are', 'not', 'required', '.', 'However', ',', 'a', 'data', 'scientist', 'is', 'most', 'likely', 'to', 'be', 'an', 'expert', 'in', 'only', 'one', 'or', 'two', 'of', 'these', 'disciplines', ',', 'meaning', 'that', 'cross', 'disciplinary', 'teams', 'can', 'be', 'a', 'key', 'component', 'of', 'data', 'science', '.', 'Good', 'data', 'scientists', 'are', 'able', 'to', 'apply', 'their', 'skills', 'to', 'achieve', 'a', 'broad', 'spectrum', 'of', 'end', 'results', '.', 'The', 'skill-sets', 'and', 'competencies', 'that', 'data', 'scientists', 'employ', 'vary', 'widely', '.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "tokens = nltk.word_tokenize(sample)\n",
    "print(\"Palabras del texto:\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio8a",
   "metadata": {},
   "source": [
    "### Apartado a\n",
    "Buscar palabras que comiencen por 'd'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ejercicio8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras que empiezan por 'd':\n",
      "['disciplines', 'data', 'disciplinary']\n"
     ]
    }
   ],
   "source": [
    "words = [w for w in tokens if re.search('^d', w)]\n",
    "print(\"Palabras que empiezan por 'd':\")\n",
    "print(list(set(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio8b",
   "metadata": {},
   "source": [
    "### Apartado b\n",
    "Buscar palabras que comiencen por 's', terminen en 'e' y tengan longitud 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ejercicio8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras que empiezan por 's', terminan en 'e' y tienen longitud 7:\n",
      "['science']\n"
     ]
    }
   ],
   "source": [
    "words = [w for w in tokens if re.search('^s.....e$', w)]\n",
    "print(\"Palabras que empiezan por 's', terminan en 'e' y tienen longitud 7:\")\n",
    "print(list(set(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_ejercicio9",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "Realizar análisis Part-of-Speech de un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ejercicio9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorías (Penn Treebank):\n",
      "[('Data', 'NNP'), ('science', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('study', 'NN'), ('of', 'IN'), ('the', 'DT'), ('extraction', 'NN'), ('of', 'IN'), ('knowledge', 'NN'), ('from', 'IN'), ('data', 'NNS'), ('.', '.')]\n",
      "[('It', 'PRP'), ('uses', 'VBZ'), ('various', 'JJ'), ('techniques', 'NNS'), ('from', 'IN'), ('many', 'JJ'), ('fields', 'NNS'), (',', ','), ('including', 'VBG'), ('signal', 'JJ'), ('processing', 'NN'), (',', ','), ('mathematics', 'NNS'), (',', ','), ('probability', 'NN'), ('models', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('computer', 'NN'), ('programming', 'NN'), (',', ','), ('statistics', 'NNS'), (',', ','), ('data', 'NNS'), ('engineering', 'NN'), (',', ','), ('pattern', 'JJ'), ('recognition', 'NN'), ('and', 'CC'), ('learning', 'NN'), (',', ','), ('visualization', 'NN'), (',', ','), ('uncertainty', 'NN'), ('modeling', 'NN'), (',', ','), ('data', 'NNS'), ('warehousing', 'NN'), (',', ','), ('and', 'CC'), ('high', 'JJ'), ('performance', 'NN'), ('computing', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('goal', 'NN'), ('of', 'IN'), ('extracting', 'VBG'), ('useful', 'JJ'), ('knowledge', 'NN'), ('from', 'IN'), ('the', 'DT'), ('data', 'NNS'), ('.', '.')]\n",
      "[('Data', 'NNP'), ('Science', 'NNP'), ('is', 'VBZ'), ('not', 'RB'), ('restricted', 'VBN'), ('to', 'TO'), ('only', 'RB'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('although', 'IN'), ('the', 'DT'), ('fact', 'NN'), ('that', 'IN'), ('data', 'NN'), ('is', 'VBZ'), ('scaling', 'VBG'), ('up', 'RP'), ('makes', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('an', 'DT'), ('important', 'JJ'), ('aspect', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('science', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('practitioner', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('science', 'NN'), ('is', 'VBZ'), ('called', 'VBN'), ('a', 'DT'), ('data', 'NN'), ('scientist', 'NN'), ('.', '.')]\n",
      "[('Data', 'NNP'), ('scientists', 'NNS'), ('solve', 'VBP'), ('complex', 'JJ'), ('data', 'NNS'), ('problems', 'NNS'), ('using', 'VBG'), ('various', 'JJ'), ('elements', 'NNS'), ('of', 'IN'), ('mathematics', 'NNS'), (',', ','), ('statistics', 'NNS'), ('and', 'CC'), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('although', 'IN'), ('expertise', 'NN'), ('in', 'IN'), ('these', 'DT'), ('subjects', 'NNS'), ('are', 'VBP'), ('not', 'RB'), ('required', 'VBN'), ('.', '.')]\n",
      "[('However', 'RB'), (',', ','), ('a', 'DT'), ('data', 'NNS'), ('scientist', 'NN'), ('is', 'VBZ'), ('most', 'RBS'), ('likely', 'JJ'), ('to', 'TO'), ('be', 'VB'), ('an', 'DT'), ('expert', 'NN'), ('in', 'IN'), ('only', 'RB'), ('one', 'CD'), ('or', 'CC'), ('two', 'CD'), ('of', 'IN'), ('these', 'DT'), ('disciplines', 'NNS'), (',', ','), ('meaning', 'VBG'), ('that', 'IN'), ('cross', 'NN'), ('disciplinary', 'JJ'), ('teams', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('a', 'DT'), ('key', 'JJ'), ('component', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('science', 'NN'), ('.', '.')]\n",
      "[('Good', 'JJ'), ('data', 'NNS'), ('scientists', 'NNS'), ('are', 'VBP'), ('able', 'JJ'), ('to', 'TO'), ('apply', 'VB'), ('their', 'PRP$'), ('skills', 'NNS'), ('to', 'TO'), ('achieve', 'VB'), ('a', 'DT'), ('broad', 'JJ'), ('spectrum', 'NN'), ('of', 'IN'), ('end', 'NN'), ('results', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('skill-sets', 'NNS'), ('and', 'CC'), ('competencies', 'NNS'), ('that', 'WDT'), ('data', 'VBP'), ('scientists', 'NNS'), ('employ', 'VBP'), ('vary', 'JJ'), ('widely', 'RB'), ('.', '.')]\n",
      "\n",
      "Categorías universales:\n",
      "[('Data', 'NOUN'), ('science', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('study', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('extraction', 'NOUN'), ('of', 'ADP'), ('knowledge', 'NOUN'), ('from', 'ADP'), ('data', 'NOUN'), ('.', '.')]\n",
      "[('It', 'PRON'), ('uses', 'VERB'), ('various', 'ADJ'), ('techniques', 'NOUN'), ('from', 'ADP'), ('many', 'ADJ'), ('fields', 'NOUN'), (',', '.'), ('including', 'VERB'), ('signal', 'ADJ'), ('processing', 'NOUN'), (',', '.'), ('mathematics', 'NOUN'), (',', '.'), ('probability', 'NOUN'), ('models', 'NOUN'), (',', '.'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', '.'), ('computer', 'NOUN'), ('programming', 'NOUN'), (',', '.'), ('statistics', 'NOUN'), (',', '.'), ('data', 'NOUN'), ('engineering', 'NOUN'), (',', '.'), ('pattern', 'ADJ'), ('recognition', 'NOUN'), ('and', 'CONJ'), ('learning', 'NOUN'), (',', '.'), ('visualization', 'NOUN'), (',', '.'), ('uncertainty', 'NOUN'), ('modeling', 'NOUN'), (',', '.'), ('data', 'NOUN'), ('warehousing', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('high', 'ADJ'), ('performance', 'NOUN'), ('computing', 'VERB'), ('with', 'ADP'), ('the', 'DET'), ('goal', 'NOUN'), ('of', 'ADP'), ('extracting', 'VERB'), ('useful', 'ADJ'), ('knowledge', 'NOUN'), ('from', 'ADP'), ('the', 'DET'), ('data', 'NOUN'), ('.', '.')]\n",
      "[('Data', 'NOUN'), ('Science', 'NOUN'), ('is', 'VERB'), ('not', 'ADV'), ('restricted', 'VERB'), ('to', 'PRT'), ('only', 'ADV'), ('big', 'ADJ'), ('data', 'NOUN'), (',', '.'), ('although', 'ADP'), ('the', 'DET'), ('fact', 'NOUN'), ('that', 'ADP'), ('data', 'NOUN'), ('is', 'VERB'), ('scaling', 'VERB'), ('up', 'PRT'), ('makes', 'VERB'), ('big', 'ADJ'), ('data', 'NOUN'), ('an', 'DET'), ('important', 'ADJ'), ('aspect', 'NOUN'), ('of', 'ADP'), ('data', 'NOUN'), ('science', 'NOUN'), ('.', '.')]\n",
      "[('A', 'DET'), ('practitioner', 'NOUN'), ('of', 'ADP'), ('data', 'NOUN'), ('science', 'NOUN'), ('is', 'VERB'), ('called', 'VERB'), ('a', 'DET'), ('data', 'NOUN'), ('scientist', 'NOUN'), ('.', '.')]\n",
      "[('Data', 'NOUN'), ('scientists', 'NOUN'), ('solve', 'VERB'), ('complex', 'ADJ'), ('data', 'NOUN'), ('problems', 'NOUN'), ('using', 'VERB'), ('various', 'ADJ'), ('elements', 'NOUN'), ('of', 'ADP'), ('mathematics', 'NOUN'), (',', '.'), ('statistics', 'NOUN'), ('and', 'CONJ'), ('computer', 'NOUN'), ('science', 'NOUN'), (',', '.'), ('although', 'ADP'), ('expertise', 'NOUN'), ('in', 'ADP'), ('these', 'DET'), ('subjects', 'NOUN'), ('are', 'VERB'), ('not', 'ADV'), ('required', 'VERB'), ('.', '.')]\n",
      "[('However', 'ADV'), (',', '.'), ('a', 'DET'), ('data', 'NOUN'), ('scientist', 'NOUN'), ('is', 'VERB'), ('most', 'ADV'), ('likely', 'ADJ'), ('to', 'PRT'), ('be', 'VERB'), ('an', 'DET'), ('expert', 'NOUN'), ('in', 'ADP'), ('only', 'ADV'), ('one', 'NUM'), ('or', 'CONJ'), ('two', 'NUM'), ('of', 'ADP'), ('these', 'DET'), ('disciplines', 'NOUN'), (',', '.'), ('meaning', 'VERB'), ('that', 'ADP'), ('cross', 'NOUN'), ('disciplinary', 'ADJ'), ('teams', 'NOUN'), ('can', 'VERB'), ('be', 'VERB'), ('a', 'DET'), ('key', 'ADJ'), ('component', 'NOUN'), ('of', 'ADP'), ('data', 'NOUN'), ('science', 'NOUN'), ('.', '.')]\n",
      "[('Good', 'ADJ'), ('data', 'NOUN'), ('scientists', 'NOUN'), ('are', 'VERB'), ('able', 'ADJ'), ('to', 'PRT'), ('apply', 'VERB'), ('their', 'PRON'), ('skills', 'NOUN'), ('to', 'PRT'), ('achieve', 'VERB'), ('a', 'DET'), ('broad', 'ADJ'), ('spectrum', 'NOUN'), ('of', 'ADP'), ('end', 'NOUN'), ('results', 'NOUN'), ('.', '.')]\n",
      "[('The', 'DET'), ('skill-sets', 'NOUN'), ('and', 'CONJ'), ('competencies', 'NOUN'), ('that', 'DET'), ('data', 'VERB'), ('scientists', 'NOUN'), ('employ', 'VERB'), ('vary', 'ADJ'), ('widely', 'ADV'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "sentences = nltk.tokenize.sent_tokenize(sample)\n",
    "\n",
    "print(\"Categorías (Penn Treebank):\")\n",
    "for sentence in sentences:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "    print(pos_tagged_tokens)\n",
    "\n",
    "print(\"\\nCategorías universales:\")\n",
    "for sentence in sentences:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tagged_tokens = nltk.pos_tag(tokens, tagset='universal')\n",
    "    print(pos_tagged_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7zqcglgmbnl",
   "metadata": {},
   "source": [
    "## Ejercicio 10\n",
    "Aplicar stemming a todos los tokens del texto en inglés utilizando el stemmer de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0k4yjafua0o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data                 -> data\n",
      "science              -> scienc\n",
      "is                   -> is\n",
      "the                  -> the\n",
      "study                -> studi\n",
      "of                   -> of\n",
      "the                  -> the\n",
      "extraction           -> extract\n",
      "of                   -> of\n",
      "knowledge            -> knowledg\n",
      "from                 -> from\n",
      "data                 -> data\n",
      ".                    -> .\n",
      "It                   -> it\n",
      "uses                 -> use\n",
      "various              -> various\n",
      "techniques           -> techniqu\n",
      "from                 -> from\n",
      "many                 -> mani\n",
      "fields               -> field\n",
      ",                    -> ,\n",
      "including            -> includ\n",
      "signal               -> signal\n",
      "processing           -> process\n",
      ",                    -> ,\n",
      "mathematics          -> mathemat\n",
      ",                    -> ,\n",
      "probability          -> probabl\n",
      "models               -> model\n",
      ",                    -> ,\n",
      "machine              -> machin\n",
      "learning             -> learn\n",
      ",                    -> ,\n",
      "computer             -> comput\n",
      "programming          -> program\n",
      ",                    -> ,\n",
      "statistics           -> statist\n",
      ",                    -> ,\n",
      "data                 -> data\n",
      "engineering          -> engin\n",
      ",                    -> ,\n",
      "pattern              -> pattern\n",
      "recognition          -> recognit\n",
      "and                  -> and\n",
      "learning             -> learn\n",
      ",                    -> ,\n",
      "visualization        -> visual\n",
      ",                    -> ,\n",
      "uncertainty          -> uncertainti\n",
      "modeling             -> model\n",
      ",                    -> ,\n",
      "data                 -> data\n",
      "warehousing          -> wareh\n",
      ",                    -> ,\n",
      "and                  -> and\n",
      "high                 -> high\n",
      "performance          -> perform\n",
      "computing            -> comput\n",
      "with                 -> with\n",
      "the                  -> the\n",
      "goal                 -> goal\n",
      "of                   -> of\n",
      "extracting           -> extract\n",
      "useful               -> use\n",
      "knowledge            -> knowledg\n",
      "from                 -> from\n",
      "the                  -> the\n",
      "data                 -> data\n",
      ".                    -> .\n",
      "Data                 -> data\n",
      "Science              -> scienc\n",
      "is                   -> is\n",
      "not                  -> not\n",
      "restricted           -> restrict\n",
      "to                   -> to\n",
      "only                 -> onli\n",
      "big                  -> big\n",
      "data                 -> data\n",
      ",                    -> ,\n",
      "although             -> although\n",
      "the                  -> the\n",
      "fact                 -> fact\n",
      "that                 -> that\n",
      "data                 -> data\n",
      "is                   -> is\n",
      "scaling              -> scale\n",
      "up                   -> up\n",
      "makes                -> make\n",
      "big                  -> big\n",
      "data                 -> data\n",
      "an                   -> an\n",
      "important            -> import\n",
      "aspect               -> aspect\n",
      "of                   -> of\n",
      "data                 -> data\n",
      "science              -> scienc\n",
      ".                    -> .\n",
      "A                    -> a\n",
      "practitioner         -> practition\n",
      "of                   -> of\n",
      "data                 -> data\n",
      "science              -> scienc\n",
      "is                   -> is\n",
      "called               -> call\n",
      "a                    -> a\n",
      "data                 -> data\n",
      "scientist            -> scientist\n",
      ".                    -> .\n",
      "Data                 -> data\n",
      "scientists           -> scientist\n",
      "solve                -> solv\n",
      "complex              -> complex\n",
      "data                 -> data\n",
      "problems             -> problem\n",
      "using                -> use\n",
      "various              -> various\n",
      "elements             -> element\n",
      "of                   -> of\n",
      "mathematics          -> mathemat\n",
      ",                    -> ,\n",
      "statistics           -> statist\n",
      "and                  -> and\n",
      "computer             -> comput\n",
      "science              -> scienc\n",
      ",                    -> ,\n",
      "although             -> although\n",
      "expertise            -> expertis\n",
      "in                   -> in\n",
      "these                -> these\n",
      "subjects             -> subject\n",
      "are                  -> are\n",
      "not                  -> not\n",
      "required             -> requir\n",
      ".                    -> .\n",
      "However              -> howev\n",
      ",                    -> ,\n",
      "a                    -> a\n",
      "data                 -> data\n",
      "scientist            -> scientist\n",
      "is                   -> is\n",
      "most                 -> most\n",
      "likely               -> like\n",
      "to                   -> to\n",
      "be                   -> be\n",
      "an                   -> an\n",
      "expert               -> expert\n",
      "in                   -> in\n",
      "only                 -> onli\n",
      "one                  -> one\n",
      "or                   -> or\n",
      "two                  -> two\n",
      "of                   -> of\n",
      "these                -> these\n",
      "disciplines          -> disciplin\n",
      ",                    -> ,\n",
      "meaning              -> mean\n",
      "that                 -> that\n",
      "cross                -> cross\n",
      "disciplinary         -> disciplinari\n",
      "teams                -> team\n",
      "can                  -> can\n",
      "be                   -> be\n",
      "a                    -> a\n",
      "key                  -> key\n",
      "component            -> compon\n",
      "of                   -> of\n",
      "data                 -> data\n",
      "science              -> scienc\n",
      ".                    -> .\n",
      "Good                 -> good\n",
      "data                 -> data\n",
      "scientists           -> scientist\n",
      "are                  -> are\n",
      "able                 -> abl\n",
      "to                   -> to\n",
      "apply                -> appli\n",
      "their                -> their\n",
      "skills               -> skill\n",
      "to                   -> to\n",
      "achieve              -> achiev\n",
      "a                    -> a\n",
      "broad                -> broad\n",
      "spectrum             -> spectrum\n",
      "of                   -> of\n",
      "end                  -> end\n",
      "results              -> result\n",
      ".                    -> .\n",
      "The                  -> the\n",
      "skill-sets           -> skill-set\n",
      "and                  -> and\n",
      "competencies         -> compet\n",
      "that                 -> that\n",
      "data                 -> data\n",
      "scientists           -> scientist\n",
      "employ               -> employ\n",
      "vary                 -> vari\n",
      "widely               -> wide\n",
      ".                    -> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Leer el archivo\n",
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "# Aplicar stemming\n",
    "stemmer = SnowballStemmer('english')\n",
    "for token in word_tokenize(sample):\n",
    "    print(f'{token:20} -> {stemmer.stem(token)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m0v0mbuvksd",
   "metadata": {},
   "source": [
    "## Ejercicio 11\n",
    "Aplicar stemming a todos los tokens del texto en español utilizando el stemmer de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mzq6p2ifchn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las                  -> las\n",
      "personas             -> person\n",
      "que                  -> que\n",
      "se                   -> se\n",
      "dedican              -> dedic\n",
      "a                    -> a\n",
      "la                   -> la\n",
      "ciencia              -> cienci\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      "se                   -> se\n",
      "les                  -> les\n",
      "conoce               -> conoc\n",
      "como                 -> com\n",
      "científico           -> cientif\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      ",                    -> ,\n",
      "de                   -> de\n",
      "acuerdo              -> acuerd\n",
      "con                  -> con\n",
      "el                   -> el\n",
      "proyecto             -> proyect\n",
      "Master               -> mast\n",
      "in                   -> in\n",
      "Data                 -> dat\n",
      "Science              -> scienc\n",
      "define               -> defin\n",
      "al                   -> al\n",
      "científico           -> cientif\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      "como                 -> com\n",
      "una                  -> una\n",
      "mezcla               -> mezcl\n",
      "de                   -> de\n",
      "estadísticos         -> estadist\n",
      ",                    -> ,\n",
      "computólogos         -> computolog\n",
      "y                    -> y\n",
      "pensadores           -> pensador\n",
      "creativos            -> creativ\n",
      ",                    -> ,\n",
      "con                  -> con\n",
      "las                  -> las\n",
      "siguientes           -> siguient\n",
      "habilidades          -> habil\n",
      ":                    -> :\n",
      "Recopilar            -> recopil\n",
      ",                    -> ,\n",
      "procesar             -> proces\n",
      "y                    -> y\n",
      "extraer              -> extra\n",
      "valor                -> valor\n",
      "de                   -> de\n",
      "las                  -> las\n",
      "diversas             -> divers\n",
      "y                    -> y\n",
      "extensas             -> extens\n",
      "bases                -> bas\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      ".                    -> .\n",
      "Imaginación          -> imagin\n",
      "para                 -> par\n",
      "comprender           -> comprend\n",
      ",                    -> ,\n",
      "visualizar           -> visualiz\n",
      "y                    -> y\n",
      "comunicar            -> comunic\n",
      "sus                  -> sus\n",
      "conclusiones         -> conclusion\n",
      "a                    -> a\n",
      "los                  -> los\n",
      "no                   -> no\n",
      "científicos          -> cientif\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      ".                    -> .\n",
      "Capacidad            -> capac\n",
      "para                 -> par\n",
      "crear                -> cre\n",
      "soluciones           -> solucion\n",
      "basadas              -> bas\n",
      "en                   -> en\n",
      "datos                -> dat\n",
      "que                  -> que\n",
      "aumentan             -> aument\n",
      "los                  -> los\n",
      "beneficios           -> benefici\n",
      ",                    -> ,\n",
      "reducen              -> reduc\n",
      "los                  -> los\n",
      "costos               -> cost\n",
      ".                    -> .\n",
      "Los                  -> los\n",
      "científicos          -> cientif\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      "trabajan             -> trabaj\n",
      "en                   -> en\n",
      "todas                -> tod\n",
      "las                  -> las\n",
      "industrias           -> industri\n",
      "y                    -> y\n",
      "hacen                -> hac\n",
      "frente               -> frent\n",
      "a                    -> a\n",
      "los                  -> los\n",
      "grandes              -> grand\n",
      "proyectos            -> proyect\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      "en                   -> en\n",
      "todos                -> tod\n",
      "los                  -> los\n",
      "niveles              -> nivel\n",
      ".                    -> .\n",
      "El                   -> el\n",
      "doctor               -> doctor\n",
      "en                   -> en\n",
      "estadística          -> estadist\n",
      "Nathan               -> nath\n",
      "Yau                  -> yau\n",
      ",                    -> ,\n",
      "precisó              -> precis\n",
      "lo                   -> lo\n",
      "siguiente            -> siguient\n",
      ":                    -> :\n",
      "el                   -> el\n",
      "científico           -> cientif\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      "es                   -> es\n",
      "un                   -> un\n",
      "estadístico          -> estadist\n",
      "que                  -> que\n",
      "debería              -> deb\n",
      "aprender             -> aprend\n",
      "interfaces           -> interfac\n",
      "de                   -> de\n",
      "programación         -> program\n",
      "de                   -> de\n",
      "aplicaciones         -> aplic\n",
      "(                    -> (\n",
      "APIs                 -> apis\n",
      ")                    -> )\n",
      ",                    -> ,\n",
      "bases                -> bas\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      "y                    -> y\n",
      "extracción           -> extraccion\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      ";                    -> ;\n",
      "es                   -> es\n",
      "un                   -> un\n",
      "diseñador            -> diseñ\n",
      "que                  -> que\n",
      "deberá               -> deb\n",
      "aprender             -> aprend\n",
      "a                    -> a\n",
      "programar            -> program\n",
      ";                    -> ;\n",
      "y                    -> y\n",
      "es                   -> es\n",
      "un                   -> un\n",
      "computólogo          -> computolog\n",
      "que                  -> que\n",
      "deberá               -> deb\n",
      "saber                -> sab\n",
      "analizar             -> analiz\n",
      "y                    -> y\n",
      "encontrar            -> encontr\n",
      "datos                -> dat\n",
      "con                  -> con\n",
      "significado          -> signific\n",
      ".                    -> .\n",
      "6                    -> 6\n",
      "En                   -> en\n",
      "la                   -> la\n",
      "tesis                -> tesis\n",
      "doctoral             -> doctoral\n",
      "de                   -> de\n",
      "Benjamin             -> benjamin\n",
      "Fry                  -> fry\n",
      "explicó              -> explic\n",
      "que                  -> que\n",
      "el                   -> el\n",
      "proceso              -> proces\n",
      "para                 -> par\n",
      "comprender           -> comprend\n",
      "mejor                -> mejor\n",
      "a                    -> a\n",
      "los                  -> los\n",
      "datos                -> dat\n",
      "comenzaba            -> comenz\n",
      "con                  -> con\n",
      "una                  -> una\n",
      "serie                -> seri\n",
      "de                   -> de\n",
      "números              -> numer\n",
      "y                    -> y\n",
      "el                   -> el\n",
      "objetivo             -> objet\n",
      "de                   -> de\n",
      "responder            -> respond\n",
      "preguntas            -> pregunt\n",
      "sobre                -> sobr\n",
      "los                  -> los\n",
      "datos                -> dat\n",
      ",                    -> ,\n",
      "en                   -> en\n",
      "cada                 -> cad\n",
      "fase                 -> fas\n",
      "del                  -> del\n",
      "proceso              -> proces\n",
      "que                  -> que\n",
      "él                   -> el\n",
      "propone              -> propon\n",
      "(                    -> (\n",
      "adquirir             -> adquir\n",
      ",                    -> ,\n",
      "analizar             -> analiz\n",
      ",                    -> ,\n",
      "filtrar              -> filtr\n",
      ",                    -> ,\n",
      "extraer              -> extra\n",
      ",                    -> ,\n",
      "representar          -> represent\n",
      ",                    -> ,\n",
      "refinar              -> refin\n",
      "e                    -> e\n",
      "interactuar          -> interactu\n",
      ")                    -> )\n",
      ",                    -> ,\n",
      "se                   -> se\n",
      "requiere             -> requier\n",
      "de                   -> de\n",
      "diferentes           -> diferent\n",
      "enfoques             -> enfoqu\n",
      "especializados       -> especializ\n",
      "que                  -> que\n",
      "aporten              -> aport\n",
      "a                    -> a\n",
      "una                  -> una\n",
      "mejor                -> mejor\n",
      "comprensión          -> comprension\n",
      "de                   -> de\n",
      "los                  -> los\n",
      "datos                -> dat\n",
      ".                    -> .\n",
      "Entre                -> entre\n",
      "los                  -> los\n",
      "enfoques             -> enfoqu\n",
      "que                  -> que\n",
      "menciona             -> mencion\n",
      "Fry                  -> fry\n",
      "están                -> estan\n",
      ":                    -> :\n",
      "ingenieros           -> ingenier\n",
      "en                   -> en\n",
      "sistemas             -> sistem\n",
      ",                    -> ,\n",
      "matemáticos          -> matemat\n",
      ",                    -> ,\n",
      "estadísticos         -> estadist\n",
      ",                    -> ,\n",
      "diseñadores          -> diseñ\n",
      "gráficos             -> grafic\n",
      ",                    -> ,\n",
      "especialistas        -> especial\n",
      "en                   -> en\n",
      "visualización        -> visualiz\n",
      "de                   -> de\n",
      "la                   -> la\n",
      "información          -> inform\n",
      "y                    -> y\n",
      "especialistas        -> especial\n",
      "en                   -> en\n",
      "interacciones        -> interaccion\n",
      "hombre-máquina       -> hombre-maquin\n",
      ",                    -> ,\n",
      "mejor                -> mejor\n",
      "conocidos            -> conoc\n",
      "por                  -> por\n",
      "sus                  -> sus\n",
      "siglas               -> sigl\n",
      "en                   -> en\n",
      "inglés               -> ingles\n",
      "“                    -> “\n",
      "HCI                  -> hci\n",
      "”                    -> ”\n",
      "(                    -> (\n",
      "Human-Computer       -> human-comput\n",
      "Interaction          -> interaction\n",
      ")                    -> )\n",
      ".                    -> .\n",
      "Además               -> ademas\n",
      ",                    -> ,\n",
      "Fry                  -> fry\n",
      "afirmó               -> afirm\n",
      "que                  -> que\n",
      "contar               -> cont\n",
      "con                  -> con\n",
      "diferentes           -> diferent\n",
      "enfoques             -> enfoqu\n",
      "especializados       -> especializ\n",
      "lejos                -> lej\n",
      "de                   -> de\n",
      "resolver             -> resolv\n",
      "el                   -> el\n",
      "problema             -> problem\n",
      "de                   -> de\n",
      "entendimiento        -> entend\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      ",                    -> ,\n",
      "se                   -> se\n",
      "convierte            -> conviert\n",
      "en                   -> en\n",
      "parte                -> part\n",
      "del                  -> del\n",
      "problema             -> problem\n",
      ",                    -> ,\n",
      "ya                   -> ya\n",
      "que                  -> que\n",
      "cada                 -> cad\n",
      "especialización      -> especializ\n",
      "conduce              -> conduc\n",
      "de                   -> de\n",
      "manera               -> maner\n",
      "aislada              -> aisl\n",
      "el                   -> el\n",
      "problema             -> problem\n",
      "y                    -> y\n",
      "el                   -> el\n",
      "camino               -> camin\n",
      "hacia                -> haci\n",
      "la                   -> la\n",
      "solución             -> solucion\n",
      "se                   -> se\n",
      "puede                -> pued\n",
      "perder               -> perd\n",
      "algo                 -> algo\n",
      "en                   -> en\n",
      "cada                 -> cad\n",
      "transición           -> transicion\n",
      "del                  -> del\n",
      "proceso              -> proces\n",
      ".                    -> .\n",
      "7                    -> 7\n",
      "en                   -> en\n",
      ":                    -> :\n",
      "Drew                 -> drew\n",
      "Conway               -> conway\n",
      "en                   -> en\n",
      "su                   -> su\n",
      "página               -> pagin\n",
      "web                  -> web\n",
      "explica              -> explic\n",
      "con                  -> con\n",
      "la                   -> la\n",
      "ayuda                -> ayud\n",
      "de                   -> de\n",
      "un                   -> un\n",
      "diagrama             -> diagram\n",
      "de                   -> de\n",
      "Venn                 -> venn\n",
      ",                    -> ,\n",
      "las                  -> las\n",
      "principales          -> principal\n",
      "habilidades          -> habil\n",
      "que                  -> que\n",
      "le                   -> le\n",
      "dan                  -> dan\n",
      "vida                 -> vid\n",
      "y                    -> y\n",
      "forma                -> form\n",
      "a                    -> a\n",
      "la                   -> la\n",
      "ciencia              -> cienci\n",
      "de                   -> de\n",
      "datos                -> dat\n",
      ",                    -> ,\n",
      "así                  -> asi\n",
      "como                 -> com\n",
      "sus                  -> sus\n",
      "relaciones           -> relacion\n",
      "de                   -> de\n",
      "conjuntos            -> conjunt\n",
      ".                    -> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Leer el archivo en español\n",
    "with open(PATH_DATA / 'Ciencia_de_datos.txt', 'r', encoding=\"utf8\") as f:\n",
    "    spanish_sample = f.read()\n",
    "\n",
    "# Aplicar stemming en español\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "for token in word_tokenize(spanish_sample):\n",
    "    print(f'{token:20} -> {stemmer.stem(token)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lf3ryfd7c4",
   "metadata": {},
   "source": [
    "## Ejercicio 12\n",
    "Realizar lematización de todos los tokens del texto en inglés utilizando WordNetLemmatizer de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ea967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Descargar recursos necesarios (si no están disponibles)\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "def wn_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'\n",
    "    if treebank_tag.startswith('V'):\n",
    "        return 'v'\n",
    "    if treebank_tag.startswith('N'):\n",
    "        return 'n'\n",
    "    if treebank_tag.startswith('R'):\n",
    "        return 'r'\n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdtoh5uqepi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token                Stem                 Lemma               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data                 dat                  data                \n",
      "science              scienc               science             \n",
      "is                   is                   be                  \n",
      "the                  the                  the                 \n",
      "study                study                study               \n",
      "of                   of                   of                  \n",
      "the                  the                  the                 \n",
      "extraction           extraction           extraction          \n",
      "of                   of                   of                  \n",
      "knowledge            knowledg             knowledge           \n",
      "from                 from                 from                \n",
      "data                 dat                  data                \n",
      ".                    .                    .                   \n",
      "it                   it                   it                  \n",
      "uses                 uses                 use                 \n",
      "various              various              various             \n",
      "techniques           techniqu             technique           \n",
      "from                 from                 from                \n",
      "many                 many                 many                \n",
      "fields               fields               field               \n",
      ",                    ,                    ,                   \n",
      "including            including            include             \n",
      "signal               signal               signal              \n",
      "processing           processing           processing          \n",
      ",                    ,                    ,                   \n",
      "mathematics          mathematics          mathematics         \n",
      ",                    ,                    ,                   \n",
      "probability          probability          probability         \n",
      "models               models               model               \n",
      ",                    ,                    ,                   \n",
      "machine              machin               machine             \n",
      "learning             learning             learning            \n",
      ",                    ,                    ,                   \n",
      "computer             comput               computer            \n",
      "programming          programming          programming         \n",
      ",                    ,                    ,                   \n",
      "statistics           statistics           statistic           \n",
      ",                    ,                    ,                   \n",
      "data                 dat                  data                \n",
      "engineering          engineering          engineering         \n",
      ",                    ,                    ,                   \n",
      "pattern              pattern              pattern             \n",
      "recognition          recognition          recognition         \n",
      "and                  and                  and                 \n",
      "learning             learning             learning            \n",
      ",                    ,                    ,                   \n",
      "visualization        visualization        visualization       \n",
      ",                    ,                    ,                   \n",
      "uncertainty          uncertainty          uncertainty         \n",
      "modeling             modeling             modeling            \n",
      ",                    ,                    ,                   \n",
      "data                 dat                  data                \n",
      "warehousing          warehousing          warehousing         \n",
      ",                    ,                    ,                   \n",
      "and                  and                  and                 \n",
      "high                 high                 high                \n",
      "performance          performanc           performance         \n",
      "computing            computing            compute             \n",
      "with                 with                 with                \n",
      "the                  the                  the                 \n",
      "goal                 goal                 goal                \n",
      "of                   of                   of                  \n",
      "extracting           extracting           extract             \n",
      "useful               useful               useful              \n",
      "knowledge            knowledg             knowledge           \n",
      "from                 from                 from                \n",
      "the                  the                  the                 \n",
      "data                 dat                  data                \n",
      ".                    .                    .                   \n",
      "data                 dat                  data                \n",
      "science              scienc               science             \n",
      "is                   is                   be                  \n",
      "not                  not                  not                 \n",
      "restricted           restrict             restrict            \n",
      "to                   to                   to                  \n",
      "only                 only                 only                \n",
      "big                  big                  big                 \n",
      "data                 dat                  data                \n",
      ",                    ,                    ,                   \n",
      "although             although             although            \n",
      "the                  the                  the                 \n",
      "fact                 fact                 fact                \n",
      "that                 that                 that                \n",
      "data                 dat                  data                \n",
      "is                   is                   be                  \n",
      "scaling              scaling              scale               \n",
      "up                   up                   up                  \n",
      "makes                mak                  make                \n",
      "big                  big                  big                 \n",
      "data                 dat                  data                \n",
      "an                   an                   an                  \n",
      "important            important            important           \n",
      "aspect               aspect               aspect              \n",
      "of                   of                   of                  \n",
      "data                 dat                  data                \n",
      "science              scienc               science             \n",
      ".                    .                    .                   \n",
      "a                    a                    a                   \n",
      "practitioner         practition           practitioner        \n",
      "of                   of                   of                  \n",
      "data                 dat                  data                \n",
      "science              scienc               science             \n",
      "is                   is                   be                  \n",
      "called               call                 call                \n",
      "a                    a                    a                   \n",
      "data                 dat                  data                \n",
      "scientist            scientist            scientist           \n",
      ".                    .                    .                   \n",
      "data                 dat                  data                \n",
      "scientists           scientists           scientist           \n",
      "solve                solv                 solve               \n",
      "complex              complex              complex             \n",
      "data                 dat                  data                \n",
      "problems             problems             problem             \n",
      "using                using                use                 \n",
      "various              various              various             \n",
      "elements             elements             element             \n",
      "of                   of                   of                  \n",
      "mathematics          mathematics          mathematics         \n",
      ",                    ,                    ,                   \n",
      "statistics           statistics           statistic           \n",
      "and                  and                  and                 \n",
      "computer             comput               computer            \n",
      "science              scienc               science             \n",
      ",                    ,                    ,                   \n",
      "although             although             although            \n",
      "expertise            expertis             expertise           \n",
      "in                   in                   in                  \n",
      "these                thes                 these               \n",
      "subjects             subjects             subject             \n",
      "are                  are                  be                  \n",
      "not                  not                  not                 \n",
      "required             requir               require             \n",
      ".                    .                    .                   \n",
      "however              howev                however             \n",
      ",                    ,                    ,                   \n",
      "a                    a                    a                   \n",
      "data                 dat                  data                \n",
      "scientist            scientist            scientist           \n",
      "is                   is                   be                  \n",
      "most                 most                 most                \n",
      "likely               likely               likely              \n",
      "to                   to                   to                  \n",
      "be                   be                   be                  \n",
      "an                   an                   an                  \n",
      "expert               expert               expert              \n",
      "in                   in                   in                  \n",
      "only                 only                 only                \n",
      "one                  one                  one                 \n",
      "or                   or                   or                  \n",
      "two                  two                  two                 \n",
      "of                   of                   of                  \n",
      "these                thes                 these               \n",
      "disciplines          disciplin            discipline          \n",
      ",                    ,                    ,                   \n",
      "meaning              meaning              mean                \n",
      "that                 that                 that                \n",
      "cross                cross                cross               \n",
      "disciplinary         disciplinary         disciplinary        \n",
      "teams                teams                team                \n",
      "can                  can                  can                 \n",
      "be                   be                   be                  \n",
      "a                    a                    a                   \n",
      "key                  key                  key                 \n",
      "component            component            component           \n",
      "of                   of                   of                  \n",
      "data                 dat                  data                \n",
      "science              scienc               science             \n",
      ".                    .                    .                   \n",
      "good                 good                 good                \n",
      "data                 dat                  data                \n",
      "scientists           scientists           scientist           \n",
      "are                  are                  be                  \n",
      "able                 able                 able                \n",
      "to                   to                   to                  \n",
      "apply                apply                apply               \n",
      "their                the                  their               \n",
      "skills               skills               skill               \n",
      "to                   to                   to                  \n",
      "achieve              achiev               achieve             \n",
      "a                    a                    a                   \n",
      "broad                bro                  broad               \n",
      "spectrum             spectrum             spectrum            \n",
      "of                   of                   of                  \n",
      "end                  end                  end                 \n",
      "results              results              result              \n",
      ".                    .                    .                   \n",
      "the                  the                  the                 \n",
      "skill-sets           skill-sets           skill-sets          \n",
      "and                  and                  and                 \n",
      "competencies         competenci           competency          \n",
      "that                 that                 that                \n",
      "data                 dat                  data                \n",
      "scientists           scientists           scientist           \n",
      "employ               employ               employ              \n",
      "vary                 vary                 vary                \n",
      "widely               widely               widely              \n",
      ".                    .                    .                   \n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo\n",
    "with open(PATH_DATA / 'Data_Science.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sample = f.read()\n",
    "\n",
    "# Aplicar lematización\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(f'{\"Token\":<20} {\"Stem\":<20} {\"Lemma\":<20}')\n",
    "for token, tag in nltk.pos_tag(nltk.word_tokenize(sample.lower())):\n",
    "    lemma = lemmatizer.lemmatize(token.lower(), wn_pos(tag))\n",
    "    print(f'{token:<20} {stemmer.stem(token):<20} {lemma:<20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8y708911qoc",
   "metadata": {},
   "source": [
    "## Ejercicio 13\n",
    "Intentar realizar lematización de tokens en español utilizando WordNetLemmatizer de NLTK (demostrando sus limitaciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cgvrxx4sxxq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token                Stem                 Lemma               \n",
      "las                  las                  la                  \n",
      "personas             person               personas            \n",
      "que                  que                  que                 \n",
      "se                   se                   se                  \n",
      "dedican              dedic                dedican             \n",
      "a                    a                    a                   \n",
      "la                   la                   la                  \n",
      "ciencia              cienci               ciencia             \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      "se                   se                   se                  \n",
      "les                  les                  le                  \n",
      "conoce               conoc                conoce              \n",
      "como                 com                  como                \n",
      "científico           cientif              científico          \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      ",                    ,                    ,                   \n",
      "de                   de                   de                  \n",
      "acuerdo              acuerd               acuerdo             \n",
      "con                  con                  con                 \n",
      "el                   el                   el                  \n",
      "proyecto             proyect              proyecto            \n",
      "master               mast                 master              \n",
      "in                   in                   in                  \n",
      "data                 dat                  data                \n",
      "science              scienc               science             \n",
      "define               defin                define              \n",
      "al                   al                   al                  \n",
      "científico           cientif              científico          \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      "como                 com                  como                \n",
      "una                  una                  una                 \n",
      "mezcla               mezcl                mezcla              \n",
      "de                   de                   de                  \n",
      "estadísticos         estadist             estadísticos        \n",
      ",                    ,                    ,                   \n",
      "computólogos         computolog           computólogos        \n",
      "y                    y                    y                   \n",
      "pensadores           pensador             pensadores          \n",
      "creativos            creativ              creativos           \n",
      ",                    ,                    ,                   \n",
      "con                  con                  con                 \n",
      "las                  las                  la                  \n",
      "siguientes           siguient             siguientes          \n",
      "habilidades          habil                habilidades         \n",
      ":                    :                    :                   \n",
      "recopilar            recopil              recopilar           \n",
      ",                    ,                    ,                   \n",
      "procesar             proces               procesar            \n",
      "y                    y                    y                   \n",
      "extraer              extra                extra               \n",
      "valor                valor                valor               \n",
      "de                   de                   de                  \n",
      "las                  las                  la                  \n",
      "diversas             divers               diversas            \n",
      "y                    y                    y                   \n",
      "extensas             extens               extensas            \n",
      "bases                bas                  base                \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      ".                    .                    .                   \n",
      "imaginación          imagin               imaginación         \n",
      "para                 par                  para                \n",
      "comprender           comprend             comprender          \n",
      ",                    ,                    ,                   \n",
      "visualizar           visualiz             visualizar          \n",
      "y                    y                    y                   \n",
      "comunicar            comunic              comunicar           \n",
      "sus                  sus                  sus                 \n",
      "conclusiones         conclusion           conclusiones        \n",
      "a                    a                    a                   \n",
      "los                  los                  los                 \n",
      "no                   no                   no                  \n",
      "científicos          cientif              científicos         \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      ".                    .                    .                   \n",
      "capacidad            capac                capacidad           \n",
      "para                 par                  para                \n",
      "crear                cre                  crear               \n",
      "soluciones           solucion             soluciones          \n",
      "basadas              bas                  basadas             \n",
      "en                   en                   en                  \n",
      "datos                dat                  datos               \n",
      "que                  que                  que                 \n",
      "aumentan             aument               aumentan            \n",
      "los                  los                  los                 \n",
      "beneficios           benefici             beneficios          \n",
      ",                    ,                    ,                   \n",
      "reducen              reduc                reducen             \n",
      "los                  los                  los                 \n",
      "costos               cost                 costos              \n",
      ".                    .                    .                   \n",
      "los                  los                  los                 \n",
      "científicos          cientif              científicos         \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      "trabajan             trabaj               trabajan            \n",
      "en                   en                   en                  \n",
      "todas                tod                  toda                \n",
      "las                  las                  la                  \n",
      "industrias           industri             industrias          \n",
      "y                    y                    y                   \n",
      "hacen                hac                  hacen               \n",
      "frente               frent                frente              \n",
      "a                    a                    a                   \n",
      "los                  los                  los                 \n",
      "grandes              grand                grandes             \n",
      "proyectos            proyect              proyectos           \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      "en                   en                   en                  \n",
      "todos                tod                  todos               \n",
      "los                  los                  los                 \n",
      "niveles              nivel                niveles             \n",
      ".                    .                    .                   \n",
      "el                   el                   el                  \n",
      "doctor               doctor               doctor              \n",
      "en                   en                   en                  \n",
      "estadística          estadist             estadística         \n",
      "nathan               nath                 nathan              \n",
      "yau                  yau                  yau                 \n",
      ",                    ,                    ,                   \n",
      "precisó              precis               precisó             \n",
      "lo                   lo                   lo                  \n",
      "siguiente            siguient             siguiente           \n",
      ":                    :                    :                   \n",
      "el                   el                   el                  \n",
      "científico           cientif              científico          \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      "es                   es                   e                   \n",
      "un                   un                   un                  \n",
      "estadístico          estadist             estadístico         \n",
      "que                  que                  que                 \n",
      "debería              deb                  debería             \n",
      "aprender             aprend               aprender            \n",
      "interfaces           interfac             interface           \n",
      "de                   de                   de                  \n",
      "programación         program              programación        \n",
      "de                   de                   de                  \n",
      "aplicaciones         aplic                aplicaciones        \n",
      "(                    (                    (                   \n",
      "apis                 apis                 apis                \n",
      ")                    )                    )                   \n",
      ",                    ,                    ,                   \n",
      "bases                bas                  base                \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      "y                    y                    y                   \n",
      "extracción           extraccion           extracción          \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      ";                    ;                    ;                   \n",
      "es                   es                   e                   \n",
      "un                   un                   un                  \n",
      "diseñador            diseñ                diseñador           \n",
      "que                  que                  que                 \n",
      "deberá               deb                  deberá              \n",
      "aprender             aprend               aprender            \n",
      "a                    a                    a                   \n",
      "programar            program              programar           \n",
      ";                    ;                    ;                   \n",
      "y                    y                    y                   \n",
      "es                   es                   es                  \n",
      "un                   un                   un                  \n",
      "computólogo          computolog           computólogo         \n",
      "que                  que                  que                 \n",
      "deberá               deb                  deberá              \n",
      "saber                sab                  saber               \n",
      "analizar             analiz               analizar            \n",
      "y                    y                    y                   \n",
      "encontrar            encontr              encontrar           \n",
      "datos                dat                  datos               \n",
      "con                  con                  con                 \n",
      "significado          signific             significado         \n",
      ".                    .                    .                   \n",
      "6                    6                    6                   \n",
      "en                   en                   en                  \n",
      "la                   la                   la                  \n",
      "tesis                tesis                tesis               \n",
      "doctoral             doctoral             doctoral            \n",
      "de                   de                   de                  \n",
      "benjamin             benjamin             benjamin            \n",
      "fry                  fry                  fry                 \n",
      "explicó              explic               explicó             \n",
      "que                  que                  que                 \n",
      "el                   el                   el                  \n",
      "proceso              proces               proceso             \n",
      "para                 par                  para                \n",
      "comprender           comprend             comprender          \n",
      "mejor                mejor                mejor               \n",
      "a                    a                    a                   \n",
      "los                  los                  los                 \n",
      "datos                dat                  datos               \n",
      "comenzaba            comenz               comenzaba           \n",
      "con                  con                  con                 \n",
      "una                  una                  una                 \n",
      "serie                seri                 serie               \n",
      "de                   de                   de                  \n",
      "números              numer                números             \n",
      "y                    y                    y                   \n",
      "el                   el                   el                  \n",
      "objetivo             objet                objetivo            \n",
      "de                   de                   de                  \n",
      "responder            respond              responder           \n",
      "preguntas            pregunt              preguntas           \n",
      "sobre                sobr                 sobre               \n",
      "los                  los                  los                 \n",
      "datos                dat                  datos               \n",
      ",                    ,                    ,                   \n",
      "en                   en                   en                  \n",
      "cada                 cad                  cada                \n",
      "fase                 fas                  fase                \n",
      "del                  del                  del                 \n",
      "proceso              proces               proceso             \n",
      "que                  que                  que                 \n",
      "él                   el                   él                  \n",
      "propone              propon               propone             \n",
      "(                    (                    (                   \n",
      "adquirir             adquir               adquirir            \n",
      ",                    ,                    ,                   \n",
      "analizar             analiz               analizar            \n",
      ",                    ,                    ,                   \n",
      "filtrar              filtr                filtrar             \n",
      ",                    ,                    ,                   \n",
      "extraer              extra                extra               \n",
      ",                    ,                    ,                   \n",
      "representar          represent            representar         \n",
      ",                    ,                    ,                   \n",
      "refinar              refin                refinar             \n",
      "e                    e                    e                   \n",
      "interactuar          interactu            interactuar         \n",
      ")                    )                    )                   \n",
      ",                    ,                    ,                   \n",
      "se                   se                   se                  \n",
      "requiere             requier              requiere            \n",
      "de                   de                   de                  \n",
      "diferentes           diferent             diferentes          \n",
      "enfoques             enfoqu               enfoques            \n",
      "especializados       especializ           especializados      \n",
      "que                  que                  que                 \n",
      "aporten              aport                aporten             \n",
      "a                    a                    a                   \n",
      "una                  una                  una                 \n",
      "mejor                mejor                mejor               \n",
      "comprensión          comprension          comprensión         \n",
      "de                   de                   de                  \n",
      "los                  los                  los                 \n",
      "datos                dat                  datos               \n",
      ".                    .                    .                   \n",
      "entre                entre                entre               \n",
      "los                  los                  los                 \n",
      "enfoques             enfoqu               enfoques            \n",
      "que                  que                  que                 \n",
      "menciona             mencion              menciona            \n",
      "fry                  fry                  fry                 \n",
      "están                estan                están               \n",
      ":                    :                    :                   \n",
      "ingenieros           ingenier             ingenieros          \n",
      "en                   en                   en                  \n",
      "sistemas             sistem               sistemas            \n",
      ",                    ,                    ,                   \n",
      "matemáticos          matemat              matemáticos         \n",
      ",                    ,                    ,                   \n",
      "estadísticos         estadist             estadísticos        \n",
      ",                    ,                    ,                   \n",
      "diseñadores          diseñ                diseñadores         \n",
      "gráficos             grafic               gráficos            \n",
      ",                    ,                    ,                   \n",
      "especialistas        especial             especialistas       \n",
      "en                   en                   en                  \n",
      "visualización        visualiz             visualización       \n",
      "de                   de                   de                  \n",
      "la                   la                   la                  \n",
      "información          inform               información         \n",
      "y                    y                    y                   \n",
      "especialistas        especial             especialistas       \n",
      "en                   en                   en                  \n",
      "interacciones        interaccion          interacciones       \n",
      "hombre-máquina       hombre-maquin        hombre-máquina      \n",
      ",                    ,                    ,                   \n",
      "mejor                mejor                mejor               \n",
      "conocidos            conoc                conocidos           \n",
      "por                  por                  por                 \n",
      "sus                  sus                  sus                 \n",
      "siglas               sigl                 siglas              \n",
      "en                   en                   en                  \n",
      "inglés               ingles               inglés              \n",
      "“                    “                    “                   \n",
      "hci                  hci                  hci                 \n",
      "”                    ”                    ”                   \n",
      "(                    (                    (                   \n",
      "human-computer       human-comput         human-computer      \n",
      "interaction          interaction          interaction         \n",
      ")                    )                    )                   \n",
      ".                    .                    .                   \n",
      "además               ademas               además              \n",
      ",                    ,                    ,                   \n",
      "fry                  fry                  fry                 \n",
      "afirmó               afirm                afirmó              \n",
      "que                  que                  que                 \n",
      "contar               cont                 contar              \n",
      "con                  con                  con                 \n",
      "diferentes           diferent             diferentes          \n",
      "enfoques             enfoqu               enfoques            \n",
      "especializados       especializ           especializados      \n",
      "lejos                lej                  lejos               \n",
      "de                   de                   de                  \n",
      "resolver             resolv               resolver            \n",
      "el                   el                   el                  \n",
      "problema             problem              problema            \n",
      "de                   de                   de                  \n",
      "entendimiento        entend               entendimiento       \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      ",                    ,                    ,                   \n",
      "se                   se                   se                  \n",
      "convierte            conviert             convierte           \n",
      "en                   en                   en                  \n",
      "parte                part                 parte               \n",
      "del                  del                  del                 \n",
      "problema             problem              problema            \n",
      ",                    ,                    ,                   \n",
      "ya                   ya                   ya                  \n",
      "que                  que                  que                 \n",
      "cada                 cad                  cada                \n",
      "especialización      especializ           especialización     \n",
      "conduce              conduc               conduce             \n",
      "de                   de                   de                  \n",
      "manera               maner                manera              \n",
      "aislada              aisl                 aislada             \n",
      "el                   el                   el                  \n",
      "problema             problem              problema            \n",
      "y                    y                    y                   \n",
      "el                   el                   el                  \n",
      "camino               camin                camino              \n",
      "hacia                haci                 hacia               \n",
      "la                   la                   la                  \n",
      "solución             solucion             solución            \n",
      "se                   se                   se                  \n",
      "puede                pued                 puede               \n",
      "perder               perd                 perder              \n",
      "algo                 algo                 algo                \n",
      "en                   en                   en                  \n",
      "cada                 cad                  cada                \n",
      "transición           transicion           transición          \n",
      "del                  del                  del                 \n",
      "proceso              proces               proceso             \n",
      ".                    .                    .                   \n",
      "7                    7                    7                   \n",
      "en                   en                   en                  \n",
      ":                    :                    :                   \n",
      "drew                 drew                 drew                \n",
      "conway               conway               conway              \n",
      "en                   en                   en                  \n",
      "su                   su                   su                  \n",
      "página               pagin                página              \n",
      "web                  web                  web                 \n",
      "explica              explic               explica             \n",
      "con                  con                  con                 \n",
      "la                   la                   la                  \n",
      "ayuda                ayud                 ayuda               \n",
      "de                   de                   de                  \n",
      "un                   un                   un                  \n",
      "diagrama             diagram              diagrama            \n",
      "de                   de                   de                  \n",
      "venn                 venn                 venn                \n",
      ",                    ,                    ,                   \n",
      "las                  las                  la                  \n",
      "principales          principal            principales         \n",
      "habilidades          habil                habilidades         \n",
      "que                  que                  que                 \n",
      "le                   le                   le                  \n",
      "dan                  dan                  dan                 \n",
      "vida                 vid                  vida                \n",
      "y                    y                    y                   \n",
      "forma                form                 forma               \n",
      "a                    a                    a                   \n",
      "la                   la                   la                  \n",
      "ciencia              cienci               ciencia             \n",
      "de                   de                   de                  \n",
      "datos                dat                  datos               \n",
      ",                    ,                    ,                   \n",
      "así                  asi                  así                 \n",
      "como                 com                  como                \n",
      "sus                  sus                  sus                 \n",
      "relaciones           relacion             relaciones          \n",
      "de                   de                   de                  \n",
      "conjuntos            conjunt              conjuntos           \n",
      ".                    .                    .                   \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Leer el archivo en español\n",
    "with open(PATH_DATA / 'Ciencia_de_datos.txt', 'r', encoding=\"utf8\") as f:\n",
    "    spanish_sample = f.read()\n",
    "\n",
    "# Aplicar lematización\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(f'{\"Token\":<20} {\"Stem\":<20} {\"Lemma\":<20}')\n",
    "for token, tag in nltk.pos_tag(nltk.word_tokenize(spanish_sample.lower())):\n",
    "    lemma = lemmatizer.lemmatize(token.lower(), wn_pos(tag))\n",
    "    print(f'{token:<20} {stemmer.stem(token):<20} {lemma:<20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1sv1ou3kktm",
   "metadata": {},
   "source": [
    "## Ejercicio 14\n",
    "Construir un lematizador personalizado para español utilizando un diccionario de lematización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eyruxsm5rp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario cargado: 491547 entradas\n"
     ]
    }
   ],
   "source": [
    "lemma_dict = {}\n",
    "with open(PATH_DATA / 'lemmatization-es.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            lemma, word = parts\n",
    "            lemma_dict[word.lower()] = lemma.lower()\n",
    "\n",
    "print(f'Diccionario cargado: {len(lemma_dict)} entradas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e32735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token                     Stem                      Lemma                    \n",
      "Las                       las                       los                      \n",
      "personas                  person                    personar                 \n",
      "que                       que                       que                      \n",
      "se                        se                        se                       \n",
      "dedican                   dedic                     dedicar                  \n",
      "a                         a                         a                        \n",
      "la                        la                        lo                       \n",
      "ciencia                   cienci                    ciencia                  \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      "se                        se                        se                       \n",
      "les                       les                       les                      \n",
      "conoce                    conoc                     conocer                  \n",
      "como                      com                       comer                    \n",
      "científico                cientif                   científico               \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      ",                         ,                         ,                        \n",
      "de                        de                        de                       \n",
      "acuerdo                   acuerd                    acordar                  \n",
      "con                       con                       con                      \n",
      "el                        el                        el                       \n",
      "proyecto                  proyect                   proyectar                \n",
      "Master                    mast                      master                   \n",
      "in                        in                        in                       \n",
      "Data                      dat                       datar                    \n",
      "Science                   scienc                    science                  \n",
      "define                    defin                     definir                  \n",
      "al                        al                        al                       \n",
      "científico                cientif                   científico               \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      "como                      com                       comer                    \n",
      "una                       una                       uno                      \n",
      "mezcla                    mezcl                     mezclar                  \n",
      "de                        de                        de                       \n",
      "estadísticos              estadist                  estadístico              \n",
      ",                         ,                         ,                        \n",
      "computólogos              computolog                computólogos             \n",
      "y                         y                         y                        \n",
      "pensadores                pensador                  pensador                 \n",
      "creativos                 creativ                   creativo                 \n",
      ",                         ,                         ,                        \n",
      "con                       con                       con                      \n",
      "las                       las                       los                      \n",
      "siguientes                siguient                  siguiente                \n",
      "habilidades               habil                     habilidad                \n",
      ":                         :                         :                        \n",
      "Recopilar                 recopil                   recopilar                \n",
      ",                         ,                         ,                        \n",
      "procesar                  proces                    procesar                 \n",
      "y                         y                         y                        \n",
      "extraer                   extra                     extraer                  \n",
      "valor                     valor                     valor                    \n",
      "de                        de                        de                       \n",
      "las                       las                       los                      \n",
      "diversas                  divers                    diverso                  \n",
      "y                         y                         y                        \n",
      "extensas                  extens                    extenso                  \n",
      "bases                     bas                       base                     \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      ".                         .                         .                        \n",
      "Imaginación               imagin                    imaginación              \n",
      "para                      par                       parir                    \n",
      "comprender                comprend                  comprender               \n",
      ",                         ,                         ,                        \n",
      "visualizar                visualiz                  visualizar               \n",
      "y                         y                         y                        \n",
      "comunicar                 comunic                   comunicar                \n",
      "sus                       sus                       su                       \n",
      "conclusiones              conclusion                conclusión               \n",
      "a                         a                         a                        \n",
      "los                       los                       lo                       \n",
      "no                        no                        no                       \n",
      "científicos               cientif                   científico               \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      ".                         .                         .                        \n",
      "Capacidad                 capac                     capacidad                \n",
      "para                      par                       parir                    \n",
      "crear                     cre                       crear                    \n",
      "soluciones                solucion                  solucionar               \n",
      "basadas                   bas                       basar                    \n",
      "en                        en                        en                       \n",
      "datos                     dat                       dato                     \n",
      "que                       que                       que                      \n",
      "aumentan                  aument                    aumentar                 \n",
      "los                       los                       lo                       \n",
      "beneficios                benefici                  beneficio                \n",
      ",                         ,                         ,                        \n",
      "reducen                   reduc                     reducir                  \n",
      "los                       los                       lo                       \n",
      "costos                    cost                      costo                    \n",
      ".                         .                         .                        \n",
      "Los                       los                       lo                       \n",
      "científicos               cientif                   científico               \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      "trabajan                  trabaj                    trabajar                 \n",
      "en                        en                        en                       \n",
      "todas                     tod                       todo                     \n",
      "las                       las                       los                      \n",
      "industrias                industri                  industriar               \n",
      "y                         y                         y                        \n",
      "hacen                     hac                       hacer                    \n",
      "frente                    frent                     frente                   \n",
      "a                         a                         a                        \n",
      "los                       los                       lo                       \n",
      "grandes                   grand                     grande                   \n",
      "proyectos                 proyect                   proyecto                 \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      "en                        en                        en                       \n",
      "todos                     tod                       todo                     \n",
      "los                       los                       lo                       \n",
      "niveles                   nivel                     nivelar                  \n",
      ".                         .                         .                        \n",
      "El                        el                        el                       \n",
      "doctor                    doctor                    doctor                   \n",
      "en                        en                        en                       \n",
      "estadística               estadist                  estadístico              \n",
      "Nathan                    nath                      nathan                   \n",
      "Yau                       yau                       yau                      \n",
      ",                         ,                         ,                        \n",
      "precisó                   precis                    precisar                 \n",
      "lo                        lo                        el                       \n",
      "siguiente                 siguient                  siguiente                \n",
      ":                         :                         :                        \n",
      "el                        el                        el                       \n",
      "científico                cientif                   científico               \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      "es                        es                        ser                      \n",
      "un                        un                        uno                      \n",
      "estadístico               estadist                  estadístico              \n",
      "que                       que                       que                      \n",
      "debería                   deb                       deber                    \n",
      "aprender                  aprend                    aprender                 \n",
      "interfaces                interfac                  interfaz                 \n",
      "de                        de                        de                       \n",
      "programación              program                   programación             \n",
      "de                        de                        de                       \n",
      "aplicaciones              aplic                     aplicación               \n",
      "(                         (                         (                        \n",
      "APIs                      apis                      apis                     \n",
      ")                         )                         )                        \n",
      ",                         ,                         ,                        \n",
      "bases                     bas                       base                     \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      "y                         y                         y                        \n",
      "extracción                extraccion                extracción               \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      ";                         ;                         ;                        \n",
      "es                        es                        ser                      \n",
      "un                        un                        uno                      \n",
      "diseñador                 diseñ                     diseñador                \n",
      "que                       que                       que                      \n",
      "deberá                    deb                       deber                    \n",
      "aprender                  aprend                    aprender                 \n",
      "a                         a                         a                        \n",
      "programar                 program                   programar                \n",
      ";                         ;                         ;                        \n",
      "y                         y                         y                        \n",
      "es                        es                        ser                      \n",
      "un                        un                        uno                      \n",
      "computólogo               computolog                computólogo              \n",
      "que                       que                       que                      \n",
      "deberá                    deb                       deber                    \n",
      "saber                     sab                       saber                    \n",
      "analizar                  analiz                    analizar                 \n",
      "y                         y                         y                        \n",
      "encontrar                 encontr                   encontrar                \n",
      "datos                     dat                       dato                     \n",
      "con                       con                       con                      \n",
      "significado               signific                  significar               \n",
      ".                         .                         .                        \n",
      "6                         6                         6                        \n",
      "En                        en                        en                       \n",
      "la                        la                        lo                       \n",
      "tesis                     tesis                     tesis                    \n",
      "doctoral                  doctoral                  doctoral                 \n",
      "de                        de                        de                       \n",
      "Benjamin                  benjamin                  benjamin                 \n",
      "Fry                       fry                       fry                      \n",
      "explicó                   explic                    explicar                 \n",
      "que                       que                       que                      \n",
      "el                        el                        el                       \n",
      "proceso                   proces                    procesar                 \n",
      "para                      par                       parir                    \n",
      "comprender                comprend                  comprender               \n",
      "mejor                     mejor                     mejor                    \n",
      "a                         a                         a                        \n",
      "los                       los                       lo                       \n",
      "datos                     dat                       dato                     \n",
      "comenzaba                 comenz                    comenzar                 \n",
      "con                       con                       con                      \n",
      "una                       una                       uno                      \n",
      "serie                     seri                      seriar                   \n",
      "de                        de                        de                       \n",
      "números                   numer                     número                   \n",
      "y                         y                         y                        \n",
      "el                        el                        el                       \n",
      "objetivo                  objet                     objetivar                \n",
      "de                        de                        de                       \n",
      "responder                 respond                   responder                \n",
      "preguntas                 pregunt                   preguntar                \n",
      "sobre                     sobr                      sobrar                   \n",
      "los                       los                       lo                       \n",
      "datos                     dat                       dato                     \n",
      ",                         ,                         ,                        \n",
      "en                        en                        en                       \n",
      "cada                      cad                       cada                     \n",
      "fase                      fas                       fase                     \n",
      "del                       del                       del                      \n",
      "proceso                   proces                    procesar                 \n",
      "que                       que                       que                      \n",
      "él                        el                        él                       \n",
      "propone                   propon                    proponer                 \n",
      "(                         (                         (                        \n",
      "adquirir                  adquir                    adquirir                 \n",
      ",                         ,                         ,                        \n",
      "analizar                  analiz                    analizar                 \n",
      ",                         ,                         ,                        \n",
      "filtrar                   filtr                     filtrar                  \n",
      ",                         ,                         ,                        \n",
      "extraer                   extra                     extraer                  \n",
      ",                         ,                         ,                        \n",
      "representar               represent                 representar              \n",
      ",                         ,                         ,                        \n",
      "refinar                   refin                     refinar                  \n",
      "e                         e                         e                        \n",
      "interactuar               interactu                 interactuar              \n",
      ")                         )                         )                        \n",
      ",                         ,                         ,                        \n",
      "se                        se                        se                       \n",
      "requiere                  requier                   requerir                 \n",
      "de                        de                        de                       \n",
      "diferentes                diferent                  diferente                \n",
      "enfoques                  enfoqu                    enfoque                  \n",
      "especializados            especializ                especializar             \n",
      "que                       que                       que                      \n",
      "aporten                   aport                     aportar                  \n",
      "a                         a                         a                        \n",
      "una                       una                       uno                      \n",
      "mejor                     mejor                     mejor                    \n",
      "comprensión               comprension               comprensión              \n",
      "de                        de                        de                       \n",
      "los                       los                       lo                       \n",
      "datos                     dat                       dato                     \n",
      ".                         .                         .                        \n",
      "Entre                     entre                     entrar                   \n",
      "los                       los                       lo                       \n",
      "enfoques                  enfoqu                    enfoque                  \n",
      "que                       que                       que                      \n",
      "menciona                  mencion                   mencionar                \n",
      "Fry                       fry                       fry                      \n",
      "están                     estan                     estar                    \n",
      ":                         :                         :                        \n",
      "ingenieros                ingenier                  ingeniero                \n",
      "en                        en                        en                       \n",
      "sistemas                  sistem                    sistema                  \n",
      ",                         ,                         ,                        \n",
      "matemáticos               matemat                   matemático               \n",
      ",                         ,                         ,                        \n",
      "estadísticos              estadist                  estadístico              \n",
      ",                         ,                         ,                        \n",
      "diseñadores               diseñ                     diseñador                \n",
      "gráficos                  grafic                    gráfico                  \n",
      ",                         ,                         ,                        \n",
      "especialistas             especial                  especialista             \n",
      "en                        en                        en                       \n",
      "visualización             visualiz                  visualización            \n",
      "de                        de                        de                       \n",
      "la                        la                        lo                       \n",
      "información               inform                    información              \n",
      "y                         y                         y                        \n",
      "especialistas             especial                  especialista             \n",
      "en                        en                        en                       \n",
      "interacciones             interaccion               interacción              \n",
      "hombre-máquina            hombre-maquin             hombre-máquina           \n",
      ",                         ,                         ,                        \n",
      "mejor                     mejor                     mejor                    \n",
      "conocidos                 conoc                     conocido                 \n",
      "por                       por                       por                      \n",
      "sus                       sus                       su                       \n",
      "siglas                    sigl                      sigla                    \n",
      "en                        en                        en                       \n",
      "inglés                    ingles                    inglés                   \n",
      "“                         “                         “                        \n",
      "HCI                       hci                       hci                      \n",
      "”                         ”                         ”                        \n",
      "(                         (                         (                        \n",
      "Human-Computer            human-comput              human-computer           \n",
      "Interaction               interaction               interaction              \n",
      ")                         )                         )                        \n",
      ".                         .                         .                        \n",
      "Además                    ademas                    además                   \n",
      ",                         ,                         ,                        \n",
      "Fry                       fry                       fry                      \n",
      "afirmó                    afirm                     afirmar                  \n",
      "que                       que                       que                      \n",
      "contar                    cont                      contar                   \n",
      "con                       con                       con                      \n",
      "diferentes                diferent                  diferente                \n",
      "enfoques                  enfoqu                    enfoque                  \n",
      "especializados            especializ                especializar             \n",
      "lejos                     lej                       lejos                    \n",
      "de                        de                        de                       \n",
      "resolver                  resolv                    resolver                 \n",
      "el                        el                        el                       \n",
      "problema                  problem                   problema                 \n",
      "de                        de                        de                       \n",
      "entendimiento             entend                    entendimiento            \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      ",                         ,                         ,                        \n",
      "se                        se                        se                       \n",
      "convierte                 conviert                  convertir                \n",
      "en                        en                        en                       \n",
      "parte                     part                      partir                   \n",
      "del                       del                       del                      \n",
      "problema                  problem                   problema                 \n",
      ",                         ,                         ,                        \n",
      "ya                        ya                        ya                       \n",
      "que                       que                       que                      \n",
      "cada                      cad                       cada                     \n",
      "especialización           especializ                especialización          \n",
      "conduce                   conduc                    conducir                 \n",
      "de                        de                        de                       \n",
      "manera                    maner                     manera                   \n",
      "aislada                   aisl                      aislar                   \n",
      "el                        el                        el                       \n",
      "problema                  problem                   problema                 \n",
      "y                         y                         y                        \n",
      "el                        el                        el                       \n",
      "camino                    camin                     caminar                  \n",
      "hacia                     haci                      hacia                    \n",
      "la                        la                        lo                       \n",
      "solución                  solucion                  solución                 \n",
      "se                        se                        se                       \n",
      "puede                     pued                      poder                    \n",
      "perder                    perd                      perder                   \n",
      "algo                      algo                      algo                     \n",
      "en                        en                        en                       \n",
      "cada                      cad                       cada                     \n",
      "transición                transicion                transición               \n",
      "del                       del                       del                      \n",
      "proceso                   proces                    procesar                 \n",
      ".                         .                         .                        \n",
      "7                         7                         7                        \n",
      "en                        en                        en                       \n",
      ":                         :                         :                        \n",
      "Drew                      drew                      drew                     \n",
      "Conway                    conway                    conway                   \n",
      "en                        en                        en                       \n",
      "su                        su                        su                       \n",
      "página                    pagin                     página                   \n",
      "web                       web                       web                      \n",
      "explica                   explic                    explicar                 \n",
      "con                       con                       con                      \n",
      "la                        la                        lo                       \n",
      "ayuda                     ayud                      ayudar                   \n",
      "de                        de                        de                       \n",
      "un                        un                        uno                      \n",
      "diagrama                  diagram                   diagrama                 \n",
      "de                        de                        de                       \n",
      "Venn                      venn                      venn                     \n",
      ",                         ,                         ,                        \n",
      "las                       las                       los                      \n",
      "principales               principal                 principal                \n",
      "habilidades               habil                     habilidad                \n",
      "que                       que                       que                      \n",
      "le                        le                        le                       \n",
      "dan                       dan                       dar                      \n",
      "vida                      vid                       vida                     \n",
      "y                         y                         y                        \n",
      "forma                     form                      formar                   \n",
      "a                         a                         a                        \n",
      "la                        la                        lo                       \n",
      "ciencia                   cienci                    ciencia                  \n",
      "de                        de                        de                       \n",
      "datos                     dat                       dato                     \n",
      ",                         ,                         ,                        \n",
      "así                       asi                       asir                     \n",
      "como                      com                       comer                    \n",
      "sus                       sus                       su                       \n",
      "relaciones                relacion                  relacionar               \n",
      "de                        de                        de                       \n",
      "conjuntos                 conjunt                   conjunto                 \n",
      ".                         .                         .                        \n"
     ]
    }
   ],
   "source": [
    "def lemmatize(word, lemma_dict):\n",
    "    return lemma_dict.get(word.lower(), word.lower())\n",
    "\n",
    "with open(PATH_DATA / 'Ciencia_de_datos.txt', 'r', encoding=\"utf8\") as f:\n",
    "    spanish_sample = f.read()\n",
    "\n",
    "print(f'{\"Token\":<25} {\"Stem\":<25} {\"Lemma\":<25}')\n",
    "for token in word_tokenize(spanish_sample, language='spanish'):\n",
    "    print(f'{token:<25} {stemmer.stem(token):<25} {lemmatize(token, lemma_dict):<25}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02-analisis-textual (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
