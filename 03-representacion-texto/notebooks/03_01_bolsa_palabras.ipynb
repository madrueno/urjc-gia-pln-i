{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c461caa",
   "metadata": {},
   "source": [
    "# Tema 3: Bolsa de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_d44cd0e7",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1c8d8",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44cd0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['de ejemplo' 'de febrero' 'de un' 'del año' 'ejemplo que' 'en febrero'\n",
      " 'es una' 'estamos finales' 'esto es' 'febrero sigue' 'finales de'\n",
      " 'frase de' 'habla de' 'haciendo frío' 'mes del' 'que habla'\n",
      " 'sigue haciendo' 'un mes' 'una frase']\n",
      "Document-Term Matrix:\n",
      " [[0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      " [1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Corpus de ejemplo\n",
    "corpus = [\n",
    "    \"Estamos a finales de febrero.\",\n",
    "    \"En febrero sigue haciendo frío.\",\n",
    "    \"Esto es una frase de ejemplo que habla de un mes del año.\",\n",
    "]\n",
    "\n",
    "# Crear el modelo de bolsa de palabras con bigramas\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Mostrar los nombres de las características y la matriz documento-término\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(\"Document-Term Matrix:\\n\", matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_6ade2139",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ade2139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['año' 'de' 'de ejemplo' 'de ejemplo que' 'de febrero' 'de un' 'de un mes'\n",
      " 'del' 'del año' 'ejemplo' 'ejemplo que' 'ejemplo que habla' 'en'\n",
      " 'en febrero' 'en febrero sigue' 'es' 'es una' 'es una frase' 'estamos'\n",
      " 'estamos finales' 'estamos finales de' 'esto' 'esto es' 'esto es una'\n",
      " 'febrero' 'febrero sigue' 'febrero sigue haciendo' 'finales' 'finales de'\n",
      " 'finales de febrero' 'frase' 'frase de' 'frase de ejemplo' 'frío' 'habla'\n",
      " 'habla de' 'habla de un' 'haciendo' 'haciendo frío' 'mes' 'mes del'\n",
      " 'mes del año' 'que' 'que habla' 'que habla de' 'sigue' 'sigue haciendo'\n",
      " 'sigue haciendo frío' 'un' 'un mes' 'un mes del' 'una' 'una frase'\n",
      " 'una frase de']\n",
      "Document-Term Matrix:\n",
      " [[0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      " [1 2 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1\n",
      "  1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Corpus de ejemplo\n",
    "corpus = [\n",
    "    \"Estamos a finales de febrero.\",\n",
    "    \"En febrero sigue haciendo frío.\",\n",
    "    \"Esto es una frase de ejemplo que habla de un mes del año.\",\n",
    "]\n",
    "\n",
    "# Crear el modelo de bolsa de palabras con bigramas\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Mostrar los nombres de las características y la matriz documento-término\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(\"Document-Term Matrix:\\n\", matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_8d1b2214",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1b2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird' 'cat' 'flying' 'in' 'jumped' 'roared' 'sky' 'the' 'tiger' 'white']\n",
      "[[0.         0.65249088 0.         0.         0.65249088 0.\n",
      "  0.         0.38537163 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.54645401\n",
      "  0.         0.32274454 0.54645401 0.54645401]\n",
      " [0.47952794 0.         0.47952794 0.47952794 0.         0.\n",
      "  0.47952794 0.28321692 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Documentos de ejemplo\n",
    "docs = [\"The cat jumped\", \"The white tiger roared\", \"Bird flying in the sky\"]\n",
    "\n",
    "# Crear un objeto TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Usar el método fit_transform para transformar los documentos en una matriz TF-IDF\n",
    "tfidf = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Mostrar el vocabulario (características) de la matriz TF-IDF\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Mostrar la matriz TF-IDF\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_5a81ebed",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b75d9a",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81ebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " al - 1\n",
      " batida - 1\n",
      " concentración - 1\n",
      " de - 7\n",
      " deporte - 1\n",
      " dobles - 1\n",
      " el - 5\n",
      " encanta - 1\n",
      " es - 6\n",
      " exigente - 1\n",
      " favorito - 2\n",
      " federer - 1\n",
      " fines - 1\n",
      " fundamental - 1\n",
      " imparable - 1\n",
      " jugar - 2\n",
      " la - 1\n",
      " los - 1\n",
      " me - 1\n",
      " mejorar - 1\n",
      " mi - 1\n",
      " mucha - 1\n",
      " muy - 1\n",
      " nadal - 1\n",
      " necesito - 1\n",
      " nueva - 1\n",
      " para - 1\n",
      " partido - 2\n",
      " pista - 1\n",
      " practicar - 1\n",
      " que - 1\n",
      " quién - 1\n",
      " raqueta - 1\n",
      " requiere - 1\n",
      " revés - 1\n",
      " saque - 1\n",
      " semana - 1\n",
      " tenis - 3\n",
      " tenista - 1\n",
      " tierra - 1\n",
      " torneo - 1\n",
      " tu - 1\n",
      " un - 2\n",
      " una - 1\n",
      " vamos - 1\n",
      " viste - 1\n",
      " wimbledon - 1\n",
      " último - 1\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"El saque de Nadal es imparable.\",\n",
    "    \"Me encanta jugar al tenis los fines de semana.\",\n",
    "    \"¿Viste el último partido de Federer?\",\n",
    "    \"Necesito una nueva raqueta de tenis.\",\n",
    "    \"El torneo de Wimbledon es mi favorito.\",\n",
    "    \"Practicar el revés es fundamental para mejorar.\",\n",
    "    \"El tenis es un deporte que requiere mucha concentración.\",\n",
    "    \"¿Quién es tu tenista favorito?\",\n",
    "    \"La pista de tierra batida es muy exigente.\",\n",
    "    \"Vamos a jugar un partido de dobles.\",\n",
    "]\n",
    "\n",
    "# Ajustar el vectorizador a los textos\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Ajustar y transformar los documentos\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Obtener los nombres de las características (vocabulario)\n",
    "nombres_caracteristicas = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Sumar las ocurrencias de cada característica en toda la colección\n",
    "frecuencias_caracteristicas = X.toarray().sum(axis=0)\n",
    "\n",
    "for i in range(len(frecuencias_caracteristicas)):\n",
    "    print(f\" {nombres_caracteristicas[i]} - {frecuencias_caracteristicas[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65dd576",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280204df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al</th>\n",
       "      <th>batida</th>\n",
       "      <th>concentración</th>\n",
       "      <th>de</th>\n",
       "      <th>deporte</th>\n",
       "      <th>dobles</th>\n",
       "      <th>el</th>\n",
       "      <th>encanta</th>\n",
       "      <th>es</th>\n",
       "      <th>exigente</th>\n",
       "      <th>...</th>\n",
       "      <th>tenista</th>\n",
       "      <th>tierra</th>\n",
       "      <th>torneo</th>\n",
       "      <th>tu</th>\n",
       "      <th>un</th>\n",
       "      <th>una</th>\n",
       "      <th>vamos</th>\n",
       "      <th>viste</th>\n",
       "      <th>wimbledon</th>\n",
       "      <th>último</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   al  batida  concentración  de  deporte  dobles  el  encanta  es  exigente  \\\n",
       "0   0       0              0   1        0       0   1        0   1         0   \n",
       "1   1       0              0   1        0       0   0        1   0         0   \n",
       "2   0       0              0   1        0       0   1        0   0         0   \n",
       "3   0       0              0   1        0       0   0        0   0         0   \n",
       "4   0       0              0   1        0       0   1        0   1         0   \n",
       "5   0       0              0   0        0       0   1        0   1         0   \n",
       "6   0       0              1   0        1       0   1        0   1         0   \n",
       "7   0       0              0   0        0       0   0        0   1         0   \n",
       "8   0       1              0   1        0       0   0        0   1         1   \n",
       "9   0       0              0   1        0       1   0        0   0         0   \n",
       "\n",
       "   ...  tenista  tierra  torneo  tu  un  una  vamos  viste  wimbledon  último  \n",
       "0  ...        0       0       0   0   0    0      0      0          0       0  \n",
       "1  ...        0       0       0   0   0    0      0      0          0       0  \n",
       "2  ...        0       0       0   0   0    0      0      1          0       1  \n",
       "3  ...        0       0       0   0   0    1      0      0          0       0  \n",
       "4  ...        0       0       1   0   0    0      0      0          1       0  \n",
       "5  ...        0       0       0   0   0    0      0      0          0       0  \n",
       "6  ...        0       0       0   0   1    0      0      0          0       0  \n",
       "7  ...        1       0       0   1   0    0      0      0          0       0  \n",
       "8  ...        0       1       0   0   0    0      0      0          0       0  \n",
       "9  ...        0       0       0   0   1    0      1      0          0       0  \n",
       "\n",
       "[10 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(X.toarray(), columns=nombres_caracteristicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_216c3fd3",
   "metadata": {},
   "source": [
    "## Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216c3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_bigrams(sentence, pad=False):\n",
    "    return list(bigrams(sentence, pad_left=pad, pad_right=pad))\n",
    "\n",
    "\n",
    "def get_trigrams(sentence, pad=False):\n",
    "    return list(trigrams(sentence, pad_left=pad, pad_right=pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5972af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ bigramas sin relleno\n",
      "[('Hoy', 'es'),\n",
      " ('es', 'un'),\n",
      " ('un', 'día'),\n",
      " ('día', 'soleado'),\n",
      " ('soleado', 'por'),\n",
      " ('por', 'fin.')]\n",
      "------------ trigramas sin relleno\n",
      "[('Hoy', 'es', 'un'),\n",
      " ('es', 'un', 'día'),\n",
      " ('un', 'día', 'soleado'),\n",
      " ('día', 'soleado', 'por'),\n",
      " ('soleado', 'por', 'fin.')]\n",
      "\n",
      "------------ bigramas con relleno\n",
      "[(None, 'Hoy'),\n",
      " ('Hoy', 'es'),\n",
      " ('es', 'un'),\n",
      " ('un', 'día'),\n",
      " ('día', 'soleado'),\n",
      " ('soleado', 'por'),\n",
      " ('por', 'fin.'),\n",
      " ('fin.', None)]\n",
      "------------ trigramas con relleno\n",
      "[(None, None, 'Hoy'),\n",
      " (None, 'Hoy', 'es'),\n",
      " ('Hoy', 'es', 'un'),\n",
      " ('es', 'un', 'día'),\n",
      " ('un', 'día', 'soleado'),\n",
      " ('día', 'soleado', 'por'),\n",
      " ('soleado', 'por', 'fin.'),\n",
      " ('por', 'fin.', None),\n",
      " ('fin.', None, None)]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hoy es un día soleado por fin.\"\n",
    "\n",
    "print(\"------------ bigramas sin relleno\")\n",
    "pprint(get_bigrams(sentence.split(\" \"), pad=False))\n",
    "\n",
    "print(\"------------ trigramas sin relleno\")\n",
    "pprint(get_trigrams(sentence.split(\" \"), pad=False))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"------------ bigramas con relleno\")\n",
    "pprint(get_bigrams(sentence.split(\" \"), pad=True))\n",
    "\n",
    "print(\"------------ trigramas con relleno\")\n",
    "pprint(get_trigrams(sentence.split(\" \"), pad=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_764abab9",
   "metadata": {},
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9535074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Frases relacionadas con el tenis\n",
    "frases = [\n",
    "    \"El saque de Nadal es imparable.\",\n",
    "    \"Me encanta jugar al tenis los fines de semana.\",\n",
    "    \"¿Viste el último partido de Federer?\",\n",
    "    \"Necesito una nueva raqueta de tenis.\",\n",
    "    \"El torneo de Wimbledon es mi favorito.\",\n",
    "    \"Practicar el revés es fundamental para mejorar.\",\n",
    "    \"El tenis es un deporte que requiere mucha concentración.\",\n",
    "    \"¿Quién es tu tenista favorito?\",\n",
    "    \"La pista de tierra batida es muy exigente.\",\n",
    "    \"Vamos a jugar un partido de dobles.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fd721",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66627dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de similitud del coseno:\n",
      "[[1.         0.13608276 0.33333333 0.16666667 0.46291005 0.3086067\n",
      "  0.27216553 0.18257419 0.28867513 0.16666667]\n",
      " [0.13608276 1.         0.13608276 0.27216553 0.12598816 0.\n",
      "  0.11111111 0.         0.11785113 0.27216553]\n",
      " [0.33333333 0.13608276 1.         0.16666667 0.3086067  0.15430335\n",
      "  0.13608276 0.         0.14433757 0.33333333]\n",
      " [0.16666667 0.27216553 0.16666667 1.         0.15430335 0.\n",
      "  0.13608276 0.         0.14433757 0.16666667]\n",
      " [0.46291005 0.12598816 0.3086067  0.15430335 1.         0.28571429\n",
      "  0.25197632 0.3380617  0.26726124 0.15430335]\n",
      " [0.3086067  0.         0.15430335 0.         0.28571429 1.\n",
      "  0.25197632 0.16903085 0.13363062 0.        ]\n",
      " [0.27216553 0.11111111 0.13608276 0.13608276 0.25197632 0.25197632\n",
      "  1.         0.1490712  0.11785113 0.13608276]\n",
      " [0.18257419 0.         0.         0.         0.3380617  0.16903085\n",
      "  0.1490712  1.         0.15811388 0.        ]\n",
      " [0.28867513 0.11785113 0.14433757 0.14433757 0.26726124 0.13363062\n",
      "  0.11785113 0.15811388 1.         0.14433757]\n",
      " [0.16666667 0.27216553 0.33333333 0.16666667 0.15430335 0.\n",
      "  0.13608276 0.         0.14433757 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir las frases a vectores de conteo binarios\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(frases)\n",
    "\n",
    "# Calcular la similitud del coseno entre las frases\n",
    "similarity_matrix = cosine_similarity(X)\n",
    "\n",
    "# Mostrar la matriz de similitud\n",
    "print(\"Matriz de similitud del coseno:\")\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfcc24",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40116eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de similitud del coseno:\n",
      "[[1.         0.13608276 0.33333333 0.16666667 0.46291005 0.3086067\n",
      "  0.27216553 0.18257419 0.28867513 0.16666667]\n",
      " [0.13608276 1.         0.13608276 0.27216553 0.12598816 0.\n",
      "  0.11111111 0.         0.11785113 0.27216553]\n",
      " [0.33333333 0.13608276 1.         0.16666667 0.3086067  0.15430335\n",
      "  0.13608276 0.         0.14433757 0.33333333]\n",
      " [0.16666667 0.27216553 0.16666667 1.         0.15430335 0.\n",
      "  0.13608276 0.         0.14433757 0.16666667]\n",
      " [0.46291005 0.12598816 0.3086067  0.15430335 1.         0.28571429\n",
      "  0.25197632 0.3380617  0.26726124 0.15430335]\n",
      " [0.3086067  0.         0.15430335 0.         0.28571429 1.\n",
      "  0.25197632 0.16903085 0.13363062 0.        ]\n",
      " [0.27216553 0.11111111 0.13608276 0.13608276 0.25197632 0.25197632\n",
      "  1.         0.1490712  0.11785113 0.13608276]\n",
      " [0.18257419 0.         0.         0.         0.3380617  0.16903085\n",
      "  0.1490712  1.         0.15811388 0.        ]\n",
      " [0.28867513 0.11785113 0.14433757 0.14433757 0.26726124 0.13363062\n",
      "  0.11785113 0.15811388 1.         0.14433757]\n",
      " [0.16666667 0.27216553 0.33333333 0.16666667 0.15430335 0.\n",
      "  0.13608276 0.         0.14433757 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir las frases a vectores de frecuencias\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(frases)\n",
    "\n",
    "# Calcular la similitud del coseno entre las frases\n",
    "similarity_matrix = cosine_similarity(X)\n",
    "\n",
    "# Mostrar la matriz de similitud\n",
    "print(\"Matriz de similitud del coseno:\")\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f1045",
   "metadata": {},
   "source": [
    "### Apartado c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764abab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de similitud del coseno:\n",
      "[[1.         0.04401798 0.14431656 0.05512477 0.20794414 0.13700281\n",
      "  0.12372398 0.07306769 0.10451453 0.05748398]\n",
      " [0.04401798 1.         0.04174201 0.13180107 0.04041363 0.\n",
      "  0.07673003 0.         0.03393445 0.16690679]\n",
      " [0.14431656 0.04174201 1.         0.05227451 0.13249941 0.07149173\n",
      "  0.06456248 0.         0.04478935 0.2202967 ]\n",
      " [0.05512477 0.13180107 0.05227451 1.         0.05061096 0.\n",
      "  0.09609085 0.         0.04249692 0.05172169]\n",
      " [0.20794414 0.04041363 0.13249941 0.05061096 1.         0.12578453\n",
      "  0.11359303 0.235307   0.09595652 0.05277699]\n",
      " [0.13700281 0.         0.07149173 0.         0.12578453 1.\n",
      "  0.10259138 0.06058741 0.04749885 0.        ]\n",
      " [0.12372398 0.07673003 0.06456248 0.09609085 0.11359303 0.10259138\n",
      "  1.         0.05471505 0.04289509 0.13091317]\n",
      " [0.07306769 0.         0.         0.         0.235307   0.06058741\n",
      "  0.05471505 1.         0.05632953 0.        ]\n",
      " [0.10451453 0.03393445 0.04478935 0.04249692 0.09595652 0.04749885\n",
      "  0.04289509 0.05632953 1.         0.0443157 ]\n",
      " [0.05748398 0.16690679 0.2202967  0.05172169 0.05277699 0.\n",
      "  0.13091317 0.         0.0443157  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir las frases a vectores TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(frases)\n",
    "\n",
    "# Calcular la similitud del coseno entre las frases\n",
    "similarity_matrix = cosine_similarity(X)\n",
    "\n",
    "# Mostrar la matriz de similitud\n",
    "print(\"Matriz de similitud del coseno:\")\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_7eedb516",
   "metadata": {},
   "source": [
    "## Ejercicio 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "262ef376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Descargar el corpus de movie_reviews, stopwords y wordnet si no están descargados\n",
    "nltk.download(\"movie_reviews\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eedb516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************\n",
      "plot : two teen couples go to a church party , drink and then drive . they get into an accident . one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . what ' s the deal ? watch the movie and \" sorta \" find out . . . critique : a mind - fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn ' t snag this one correctly . they seem to have taken this pretty neat concept , but executed it terribly . so what are the problems with the movie ? well , its main problem is that it ' s simply too jumbled . it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what ' s going on . there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . now i personally don ' t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film ' s biggest problem . it ' s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . and do they make things entertaining , thrilling or even engaging , in the meantime ? not really . the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half - way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn ' t the make the film all that more entertaining . i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! okay , we get it . . . there are people chasing her and we don ' t know who they are . do we really need to see it over and over again ? how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? apparently , the studio took this film away from its director and chopped it up themselves , and it shows . there might ' ve been a pretty decent teen mind - fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character ' s unraveling . overall , the film doesn ' t stick because it doesn ' t entertain , it ' s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . oh , and by the way , this is not a horror or teen slasher flick . . . it ' s just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . it also wrapped production two years ago and has been sitting on the shelves ever since . whatever . . . skip it ! where ' s joblo coming from ? a nightmare of elm street 3 ( 7 / 10 ) - blair witch 2 ( 7 / 10 ) - the crow ( 9 / 10 ) - the crow : salvation ( 4 / 10 ) - lost highway ( 10 / 10 ) - memento ( 10 / 10 ) - the others ( 9 / 10 ) - stir of echoes ( 8 / 10 )\n",
      "*******************************************\n",
      "*******************************************\n",
      "the happy bastard ' s quick movie review damn that y2k bug . it ' s got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . little do they know the power within . . . going for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . we don ' t know why the crew was really out in the middle of nowhere , we don ' t know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don ' t know why donald sutherland is stumbling around drunkenly throughout . here , it ' s just \" hey , let ' s chase these people around with some robots \" . the acting is below average , even from the likes of curtis . you ' re more likely to get a kick out of her work in halloween h20 . sutherland is wasted and baldwin , well , he ' s acting like a baldwin , of course . the real star here are stan winston ' s robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone ' s brain . so , if robots and body parts really turn you on , here ' s your movie . otherwise , it ' s pretty much a sunken ship of a movie .\n",
      "*******************************************\n",
      "*******************************************\n",
      "it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . based on the late 1960 ' s television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . however , things go wrong as evidence gets stolen and they are immediately under suspicion . of course , the ads make it seem like so much more . quick cuts , cool music , claire dane ' s nice hair and cute outfits , car chases , stuff blowing up , and the like . sounds like a cool movie , does it not ? after the first fifteen minutes , it quickly becomes apparent that it is not . the mod squad is certainly a slick looking production , complete with nice hair and costumes , but that simply isn ' t enough . the film is best described as a cross between an hour - long cop show and a music video , both stretched out into the span of an hour and a half . and with it comes every single clich ? . it doesn ' t really matter that the film is based on a television show , as most of the plot elements have been recycled from everything we ' ve already seen . the characters and acting is nothing spectacular , sometimes even bordering on wooden . claire danes and omar epps deliver their lines as if they are bored , which really transfers onto the audience . the only one to escape relatively unscathed is giovanni ribisi , who plays the resident crazy man , ultimately being the only thing worth watching . unfortunately , even he ' s not enough to save this convoluted mess , as all the characters don ' t do much apart from occupying screen time . with the young cast , cool clothes , nice hair , and hip soundtrack , it appears that the film is geared towards the teenage mindset . despite an american ' r ' rating ( which the content does not justify ) , the film is way too juvenile for the older mindset . information on the characters is literally spoon - fed to the audience ( would it be that hard to show us instead of telling us ? ) , dialogue is poorly written , and the plot is extremely predictable . the way the film progresses , you likely won ' t even care if the heroes are in any jeopardy , because you ' ll know they aren ' t . basing the show on a 1960 ' s television show that nobody remembers is of questionable wisdom , especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand ( even one that ' s missing a finger or two ) . the number of times that i checked my watch ( six ) is a clear indication that this film is not one of them . it is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar , judging from the rash of really awful teen - flicks that we ' ve been seeing as of late . avoid this film at all costs .\n",
      "*******************************************\n",
      "*******************************************\n",
      "\" quest for camelot \" is warner bros . ' first feature - length , fully - animated attempt to steal clout from disney ' s cartoon empire , but the mouse has no reason to be worried . the only other recent challenger to their throne was last fall ' s promising , if flawed , 20th century fox production \" anastasia , \" but disney ' s \" hercules , \" with its lively cast and colorful palate , had her beat hands - down when it came time to crown 1997 ' s best piece of animation . this year , it ' s no contest , as \" quest for camelot \" is pretty much dead on arrival . even the magic kingdom at its most mediocre -- that ' d be \" pocahontas \" for those of you keeping score -- isn ' t nearly as dull as this . the story revolves around the adventures of free - spirited kayley ( voiced by jessalyn gilsig ) , the early - teen daughter of a belated knight from king arthur ' s round table . kayley ' s only dream is to follow in her father ' s footsteps , and she gets her chance when evil warlord ruber ( gary oldman ) , an ex - round table member - gone - bad , steals arthur ' s magical sword excalibur and accidentally loses it in a dangerous , booby - trapped forest . with the help of hunky , blind timberland - dweller garrett ( carey elwes ) and a two - headed dragon ( eric idle and don rickles ) that ' s always arguing with itself , kayley just might be able to break the medieval sexist mold and prove her worth as a fighter on arthur ' s side . \" quest for camelot \" is missing pure showmanship , an essential element if it ' s ever expected to climb to the high ranks of disney . there ' s nothing here that differentiates \" quest \" from something you ' d see on any given saturday morning cartoon -- subpar animation , instantly forgettable songs , poorly - integrated computerized footage . ( compare kayley and garrett ' s run - in with the angry ogre to herc ' s battle with the hydra . i rest my case . ) even the characters stink -- none of them are remotely interesting , so much that the film becomes a race to see which one can out - bland the others . in the end , it ' s a tie -- they all win . that dragon ' s comedy shtick is awfully cloying , but at least it shows signs of a pulse . at least fans of the early -' 90s tgif television line - up will be thrilled to find jaleel \" urkel \" white and bronson \" balki \" pinchot sharing the same footage . a few scenes are nicely realized ( though i ' m at a loss to recall enough to be specific ) , and the actors providing the voice talent are enthusiastic ( though most are paired up with singers who don ' t sound a thing like them for their big musical moments -- jane seymour and celine dion ? ? ? ) . but one must strain through too much of this mess to find the good . aside from the fact that children will probably be as bored watching this as adults , \" quest for camelot \" ' s most grievous error is its complete lack of personality . and personality , we learn from this mess , goes a very long way .\n",
      "*******************************************\n",
      "*******************************************\n",
      "synopsis : a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal accident and then falls in love with the boy ' s mother , a fledgling restauranteur . unsuccessfully attempting to gain the woman ' s favor , he takes pictures of her and kills a number of people in his way . comments : stalked is yet another in a seemingly endless string of spurned - psychos - getting - their - revenge type movies which are a stable category in the 1990s film industry , both theatrical and direct - to - video . their proliferation may be due in part to the fact that they ' re typically inexpensive to produce ( no special effects , no big name stars ) and serve as vehicles to flash nudity ( allowing them to frequent late - night cable television ) . stalked wavers slightly from the norm in one respect : the psycho never actually has an affair ; on the contrary , he ' s rejected rather quickly ( the psycho typically is an ex - lover , ex - wife , or ex - husband ) . other than that , stalked is just another redundant entry doomed to collect dust on video shelves and viewed after midnight on cable . stalked does not provide much suspense , though that is what it sets out to do . interspersed throughout the opening credits , for instance , a serious - sounding narrator spouts statistics about stalkers and ponders what may cause a man to stalk ( it ' s implicitly implied that all stalkers are men ) while pictures of a boy are shown on the screen . after these credits , a snapshot of actor jay underwood appears . the narrator states that \" this is the story of daryl gleason \" and tells the audience that he is the stalker . of course , really , this is the story of restauranteur brooke daniels . if the movie was meant to be about daryl , then it should have been called stalker not stalked . okay . so we know who the stalker is even before the movie starts ; no guesswork required . stalked proceeds , then , as it begins : obvious , obvious , obvious . the opening sequence , contrived quite a bit , brings daryl and brooke ( the victim ) together . daryl obsesses over brooke , follows her around , and tries to woo her . ultimately rejected by her , his plans become more and more desperate and elaborate . these plans include the all - time , psycho - in - love , cliche : the murdered pet . for some reason , this genre ' s films require a dead pet to be found by the victim stalked . stalked is no exception ( it ' s a cat this time -- found in the shower ) . events like these lead to the inevitable showdown between stalker and stalked , where only one survives ( guess who it invariably always is and you ' ll guess the conclusion to this turkey ) . stalked ' s cast is uniformly adequate : not anything to write home about but also not all that bad either . jay underwood , as the stalker , turns toward melodrama a bit too much . he overdoes it , in other words , but he still manages to be creepy enough to pass as the type of stalker the story demands . maryam d ' abo , about the only actor close to being a star here ( she played the bond chick in the living daylights ) , is equally adequate as the \" stalked \" of the title , even though she seems too ditzy at times to be a strong , independent business - owner . brooke ( d ' abo ) needs to be ditzy , however , for the plot to proceed . toward the end , for example , brooke has her suspicions about daryl . to ensure he won ' t use it as another excuse to see her , brooke decides to return a toolbox he had left at her place to his house . does she just leave the toolbox at the door when no one answers ? of course not . she tries the door , opens it , and wanders around the house . when daryl returns , he enters the house , of course , so our heroine is in danger . somehow , even though her car is parked at the front of the house , right by the front door , daryl is oblivious to her presence inside . the whole episode places an incredible strain on the audience ' s suspension of disbelief and questions the validity of either character ' s intelligence . stalked receives two stars because , even though it is highly derivative and somewhat boring , it is not so bad that it cannot be watched . rated r mostly for several murder scenes and brief nudity in a strip bar , it is not as offensive as many other thrillers in this genre are . if you ' re in the mood for a good suspense film , though , stake out something else .\n",
      "*******************************************\n",
      "*******************************************\n",
      "capsule : in 2176 on the planet mars police taking into custody an accused murderer face the title menace . there is a lot of fighting and not a whole lot of story otherwise . john carpenter reprises so many ideas from his previous films , especially assault on precinct 13 , that the new film comes off as his homage to himself . , 0 ( - 4 to + 4 ) . john carpenter apparently believes that action scenes in which people fight something horrible are the same as horror scenes . for a writer and director of horror films , supposedly an expert on horror , it is a very bad mistake to make . ghosts of mars is called a horror movie , but it is more just a drawn out fight between humans and a surprisingly low - powered alien menace . in addition if anybody but john carpenter had made ghosts of mars , carpenter would have grounds to sue . this film is just chock full of pieces taken from assault on precinct 13 , the thing , and prince of darkness . it is , in fact , surprising that carpenter managed to fit so many pieces of his previous work into this film in such an admittedly novel way . but that still does not make for a really good science fiction experience . ghosts of mars takes place in the year 2176 . mars has been mostly terraformed so that humans can walk on the surface without breathing gear ( which is good for the film ' s budget ) . it is never mentioned , but the gravity on mars has been increased somehow to earth - normal , again making it easier to film . society has changed a bit by that time , but it has advanced surprisingly little . apparently the culture has changed so that women are much more in positions of control . and from carpenter ' s view , women have really made a mess of things . society has stagnated under female control so that beyond some minor technological advances society has changed less in 175 years than we might expect it to change in ten . the basic plot of ghosts of mars has much in common with that of assault on precinct 13 except that precinct 9 ( yes , precinct 9 ) has been replaced by a somewhat tacky looking rundown martian mining colony . instead of having the criminal \" napolean \" wilson , this film has the criminal \" desolation \" williams . instead of facing hoodlums with automatic weapons the police face , well , ghosts of mars . because the ghosts are somewhat alien in nature they should behave in some alien manner , but they essentially behave as human savages , in another lapse of imagination . the story is told in flashback , flashback within flashback , and flashback within flashback within flashback . ghosts of mars takes place entirely at night and is filmed almost entirely in tones of red , yellow , and black . carpenter manages to give us a powerful opening scene , showing a mining train rushing through the martian night to the sound of music with a heavy beat . sadly what follows is not really up to the buildup . the terror he creates looks a little too much like fugitive wannabes from the rock band kiss . his idea of building suspense is having a bunch of sudden jump scenes that sucker the viewer into thinking something scary is happening and then prove to be just something boring . these are standard haunted house film shock effects that require no great talent to give the audience . somewhat newer but also unimpressive are the cgi digital decapitations in some of the fights . within a short stretch of time we have seen the release of mission to mars , red planet , and ghosts of mars . after mission to mars was panned by too many reviewers it looks better and better and better as time goes by . i rate ghosts of mars a 4 on the 0 to 10 scale and a 0 on the - 4 to + 4 scale . following the movie i showed my wife , who liked ghosts of mars moderately more than i did , carpenter ' s classic assault on precinct 13 . her comment is that it was seeing the same film twice .\n",
      "*******************************************\n",
      "*******************************************\n",
      "so ask yourself what \" 8mm \" ( \" eight millimeter \" ) is really all about . is it about a wholesome surveillance man who loses sight of his values after becoming enmeshed in the seedy , sleazy underworld of hardcore pornography ? is it about the business itself , how , bubbling just beneath the surface of big - town americana , there ' s a sordid world of sick and depraved people who won ' t necessarily stop short of murder in order to satisfy their sick and twisted desires ? or is it about those who can , those who are in a position to influence the making of the kinds of films sick and demented people want to see ? i ' m not talking about snuff films , supposed \" documentaries \" of victims being brutalized and killed on camera . i ' m talking about films like \" 8mm \" and its director , joel schumacher . with a recent run of big budget movies to his credit -- \" batman & robin , \" \" a time to kill , \" \" batman forever , \" \" the client \" -- schumacher certainly has that kind of influence . is \" 8mm \" something you really want to see ? probably not . the first two - thirds of \" 8mm \" unwind as a fairly conventional missing persons drama , albeit with a particularly unsavory core . then , as it ' s been threatening all along , the film explodes into violence . and just when you think it ' s finally over , schumacher tags on a ridiculous self - righteous finale that drags the whole unpleasant experience down even further . trust me . there are better ways to waste two hours of your life . nicolas ' \" snake eyes \" ' cage plays private investigator tom welles who is hired by a wealthy philadelphia widow to determine whether a reel of film found in her late husband ' s safe documents a young girl ' s murder . welles goes about his assignment rather matter - of - factly , and the pieces of the puzzle fall into place rather neatly , almost as if you don ' t need any specialized skills or training to do this . welles certainly makes it look easy . and cops , obviously , never look in toilet tanks for clues . the deeper welles digs into his investigation the more obsessed he becomes , like george c . scott in paul schrader ' s \" hardcore . \" occasionally , a little flickering sound whirs in his head like sprockets winding through a film projector , reminding him of his unpleasant task . there are hints that this is taking its toll on his lovely wife , played by catherine keener , who is frustrated by her husband spending all of his time in cleveland rather than in their ugly split - level home in harrisburg , pa . \" 8mm \" doesn ' t condemn or condone its subject matter , it just exploits it . the irony , of course , is that schumacher and \" seven \" scribe andrew kevin walker ' s vision of life in the snuff lane is limited by what they can show in an r - rated , first - run hollywood product . so we only see snippets of snuff , and a lot more footage of nicolas cage covering his face in horror . later it ' s the turn of joaquin phoenix ( who ' s quite good and by far the film ' s most interesting character as adult bookstore flunky max california ) to cover his face as the horrid thing is screened over and over again . all this to get to the familiar yet offensive \" revelation \" that sexual deviants are not , indeed , monsters but everyday people like you and me . neither super nor standard , \" 8mm \" is shocking only in its banality .\n",
      "*******************************************\n",
      "*******************************************\n",
      "that ' s exactly how long the movie felt to me . there weren ' t even nine laughs in nine months . it ' s a terrible mess of a movie starring a terrible mess of a man , mr . hugh grant , a huge dork . it ' s not the whole oral - sex / prostitution thing ( referring to grant , not me ) that bugs me , it ' s the fact that grant is annoying . not just adam sandler - annoying , we ' re talking jim carrey - annoying . since when do eye flutters and nervous smiles pass for acting ? but , on the other hand , since when do really bad slapstick ( a fistfight in the delivery room culminating in grant ' s head in joan cusack ' s lap -- a scene he paid $ 60 to have included in the movie ) and obscene double entendres ( robin williams , the obstetrician , tells grant ' s pregnant girlfriend she has \" a big pussy , \" referring of course to the size of the cat hairs on her coat , but nonetheless , grant paid $ 60 to have the exchange included in the movie ) pass for comedy ? nine months is a predictable cookie - cutter movie with no originality in humor or plot . hugh grant plays a successful child psychiatrist . why a child psychologist ? so the scriptwriters could inject the following unfunny exchange : kid : my dad ' s an asshole . grant ( flutters eyelashes , offers a nervous smile , then responds in his annoying english accent and i - think - i - actually - have - talent attitude ) : could you possibly elaborate on that ? kid : my dad ' s a _huge_ asshole . more like a hugh asshole , but that ' s beside the point , which is : nine months includes too many needlessly stupid jokes that get laughs from the ten year olds in the audience while everyone else shakes his or her head in disbelief . so , anyway , grant finds out his girlfriend is pregnant and does his usual reaction ( fluttered eyelashes , nervous smiles ) . this paves the way for every possible pregnancy / child birth gag in the book , especially since grant ' s equally annoying friend ' s wife is also pregnant . the annoying friend is played by tom arnold , who provides most of the cacophonous slapstick , none of which is funny , such as a scene where arnold beats up a costumed \" arnie the dinosaur \" ( you draw your own parallels on that one ) in a toy store . the only interesting character in the movie is played by jeff goldblum , who should have hid himself away somewhere after the dreadful hideaway , as an artist with a fear of ( and simultaneous longing for ) commitment . not even robin williams , who plays a russian doctor who has recently decided to switch from veterinary medicine to obstetrics , has much humor . his is a one - joke character -- the old foreign - guy - who - mispronounces - english stereotype ( did someone say yakov smirnov ? that ' s my favorite vodka , by the way ) , hence the line \" now it ' s time to take a look at your volvo , \" another nasty but unamusing joke , except this one goes right over the ten year olds ' heads , while the adults simultaneously groan . nine months is a complete failure , low on laughs and intelligence and high on loud , unfunny slapstick , failed jokes and other uninspired lunacy . hugh grant ' s sunset boulevard arrest ( please , no caught - with - his - pants - down jokes ) may bring more people into the theaters , but they certainly won ' t leave with a smile on their faces , not after 90 minutes of grant ' s nervous smiles . everything in the movie is so forced , so unauthentic that anyone with an i . q . over 80 ( sorry , hugh ) will know they wasted their money on an unfulfilled desire . but at least they didn ' t spend 60 bucks for it .\n",
      "*******************************************\n",
      "*******************************************\n",
      "call it a road trip for the walking wounded . stellan skarsg ? rd plays such a convincingly zombified drunken loser that it ' s difficult to spend nearly two hours of screen time in his smelly , boozed - out presence . yet this ever - reliable swedish actor adds depth and significance to the otherwise plodding and forgettable aberdeen , a sentimental and painfully mundane european drama . playwright august strindberg built his career on families and relationships paralyzed by secrets , unable to express their longings until the hour is far too late . that ' s an accurate reflection of what aberdeen strives for , focusing on the pairing of an alcoholic father , tomas ( skarsg ? rd ) and his alienated , openly hostile yuppie daughter , kaisa ( lena headey , gossip ) . they haven ' t spoken in years , and wouldn ' t even be making the long trip from norway to aberdeen , scotland by automobile if it weren ' t for kaisa ' s mother ( charlotte rampling , under the sand ) rotting away in a hospital bed from cancer . in a soap opera twist , mother has only a few days to live . ( only in the movies , right ? ) too blitzed to even step foot on a plane , tomas hits the open road with kaisa . loathing each other all the while , they make periodic stops for tomas to puke on the dashboard or pass out -- whenever he isn ' t muttering what a rotten kid she turned out to be . despite his sloshed viewpoint , tomas recognizes that the apple hasn ' t fallen very far from the tree . kaisa gets nosebleeds from snorting coke , sabotages her personal relationships through indifference , and is unable to restrain her quick and vindictive temper . ain ' t they a pair ? unable to find true notes of unspoken familial empathy in the one - note and repetitively bitchy dialogue , screenwriters kristin amundsen and hans petter moland fabricate a series of contrivances to propel events forward -- lost money , roving street hooligans looking for drunks to kick around , nosy cops , and flat tires all figure into the schematic and convenient narrative . by the time they reach the hospital , it ' s time to unveil the secrets from a dark past that are not only simplistic devices that trivialize the father - daughter conflict , they ' re also the mainstays of many a bad strindberg wannabe . this revelation exists purely for its own sake . aberdeen doesn ' t know where else to go . weak , unimaginative casting thwarts the pivotal role of kaisa . if lena headey were a stronger actress , perhaps aberdeen could have been able to coast on the performances and moody , haunting cinematography ( rendering norway into its own pastoral ghost world -- the reference to a certain superior american indie flick intentional ) . headey ' s too busy acting , using her face and furrowed brow to convey every last twitch of insouciance . if she were paying any attention to skarsg ? rd , maybe she ' d figure out that doing less can reveal so much more . it ' s worthwhile to compare aberdeen to an earlier film released in 2001 , jonathan nossiter ' s captivating signs & wonders . it ' s not just because skarsg ? rd and rampling played disturbed parental figures in both films ( they ' re not bound by ceremonial wedlock in aberdeen ) . the differences in the way their characters were presented is significant . in aberdeen , rampling is a luminous diva , preening and static in her hospital bed . despite skarsg ? rd ' s solid performance as tomas , his pathetic drunk is never given much of a chance to emote anything besides catatonic sorrow . there ' s genuine ferocity and sexually charged frisson during their understated confrontations in signs & wonders , allowing them to suggest a gray zone of complications that accompany torn romance and years of stifled curiosity . nossiter ' s film thoroughly explores this neurotic territory in addition to delving into the americanization of greece and the use of mysticism as an illusion to deflect pain . if signs & wonders sometimes feels overloaded with ideas , at least it ' s willing to stretch beyond what we ' ve come to expect from traditional drama . aberdeen is never half so ambitious , content to sleepwalk through the rhythms and timing of other movies . when did character driven stories stop paying attention to the complexities of real life ? the depressing answer can be found in lawrence kasdan ' s trite but occasionally useful grand canyon , where steve martin ' s hollywood mogul pronounces , \" all of life ' s riddles are answered in the movies ! \" even foreign films are taking that advice to heart .\n",
      "*******************************************\n",
      "*******************************************\n",
      "plot : a young french boy sees his parents killed before his eyes by tim roth , oops . . . i mean , an evil man . he vows revenge on that man and is taught the ways of the musketeer by some old dude who used to be one himself ? anyway , fourteen years go by and . . . arrgh , well , you know the rest . . . swish - swish - zzzzzzz ! critique : this is a pretty bad movie . let ' s see , where should i start ? okay , first of all , the story is just plain boring . it ' s not original , is entirely predictable and lacks energy . okay , what ' s next ? acting , you say . hmmmm , well , the main actor , justin chambers , is basically an uncharismatic version of chris o ' donnell but with less range ( think about that ! ) , and mena suvari , is just plain off . not as bad as thora birch was in dungeons & dragons , but entirely miscast , with bad deliveries , awful sequences and a piss - poor accent that comes and goes . now i ' m not sure if this was ms . suvari ' s fault or the director ' s , but i ' ve definitely seen her at a much higher level than in this film . the only semi - saving grace actor - wise is tim roth as the irrepressible \" bad guy \" , but once again , it ' s not something that we haven ' t seen before . . . a thousand times . . . by the same guy ! ! tim , please . . . for the love of god , beg your agent to ask the marketplace for some modern day \" american roles \" for you as a \" nice guy \" in a romantic comedy or something . stretch , dude . . . stretch ! ! we all know that you can do much better than this gunk . alright , what else was bad in this film ? oh yeah , the score ! yikes , how ' s about taking it down a few notches there , fellas ? this thing blares in your ear whenever it feels the need to accentuate a certain scene , but actually does little more than annoy . i think it ' s important for the man behind the music to recognize that this film isn ' t a \" real epic \" by any stretch of the imagination . it ' s a fluffy rehashed cake - walk created by some \" shrewd \" studio heads who decided to take advantage of the whole \" kung - fu \" phenomenon in films , and test it out on an old classic . dudes . . . you failed all around ! ( keep reading ) the editing is also pretty shoddy in this movie , the dialogue banal and stilted and the plot problems . . . plentiful ! ( why does the guy on top of the horse carriage just stand there when his opponent takes forever scampering his way back to the top ? why don ' t they just cut the mouseketeer ' s rope at the top of the tower , instead of jumping down on their own chords and fighting him while hanging ? why doesn ' t anybody look a day older , when the sequence says \" 14 years later \" ? ( at least . . . change your shirt , man ! ) keep in mind that i have never strayed away from championing certain movies that are created simply for the sake of a \" fun time \" , but this flick just didn ' t cut it for me . it was boring for stretches , the acting was atrocious at times ( the \" romantic \" scene between suvari and chambers next to the lake reminded me of plays in high school which made you cringe ) , there was little reason to care for anyone and since when were the musketeers fat ? i will give the movie this much , and that is that its main reason for being ( its \" raison - d ' etre \" , as the french would say ) , its fight sequences , do come through despite the lack of their numbers in the film . i was hoping that the movie would be packed with cool stuntwork as promoted in its trailer , but what you see there , are essentially the snippets from the two major ( and cool ) swashbuckling sequences from the film . the first comes right at the beginning of the movie , while the other essentially finishes the film off , hanging from the tower and juggling off ladders . the ladder sequence itself is a definite keeper but unfortunately the rest of the movie is just regurgitated crap . and can anyone please tell me how catherine deneuve got her name placed at the top of this film ' s credits ? hullo ? the film is called the musketeer and stars a dude name justin chambers . deneuve is barely in this movie ! ugh , just another small thing that annoyed me about this trash . now say it together , gang : \" all for one , and one for all . . . we vow to stay away from it all ! ! \" thank me later . where ' s joblo coming from ? a knight ' s tale ( 7 / 10 ) - american outlaws ( 5 / 10 ) - crouching tiger , hidden dragon ( 7 / 10 ) - the matrix ( 8 / 10 ) - the replacement killers ( 6 / 10 ) - romeo must die ( 3 / 10 ) - shanghai noon ( 6 / 10 )\n",
      "*******************************************\n",
      "Count Vectorizer (binary): 0.8325\n",
      "Count Vectorizer (frequency): 0.8150\n",
      "TF-IDF Vectorizer: 0.8075\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos y etiquetas del corpus de movie_reviews\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "\n",
    "# Convertir los documentos en texto y las etiquetas en una lista\n",
    "texts = [\" \".join(doc) for doc, _ in documents]\n",
    "\n",
    "for text in texts[:10]:\n",
    "    print(\"*******************************************\")\n",
    "    print(text)\n",
    "    print(\"*******************************************\")\n",
    "\n",
    "\n",
    "labels = [category for _, category in documents]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con una función de pesado específica\n",
    "def train_and_evaluate(vectorizer):\n",
    "    # Vectorizar los textos de entrenamiento y prueba\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Entrenar un clasificador Naive Bayes\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Predecir las etiquetas del conjunto de prueba\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluar el modelo con diferentes funciones de pesado\n",
    "vectorizers = {\n",
    "    \"Count Vectorizer (binary)\": CountVectorizer(binary=True),\n",
    "    \"Count Vectorizer (frequency)\": CountVectorizer(),\n",
    "    \"TF-IDF Vectorizer\": TfidfVectorizer(),\n",
    "}\n",
    "\n",
    "accuracies = {\n",
    "    name: train_and_evaluate(vectorizer) for name, vectorizer in vectorizers.items()\n",
    "}\n",
    "\n",
    "# Imprimir los resultados\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "808ce930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer (binary): 0.8300\n",
      "Count Vectorizer (frequency): 0.8125\n",
      "TF-IDF Vectorizer: 0.7950\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Cargar los datos y etiquetas del corpus de movie_reviews\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "\n",
    "# Convertir los documentos en texto y las etiquetas en una lista\n",
    "texts = [\" \".join(doc) for doc, _ in documents]\n",
    "labels = [category for _, category in documents]\n",
    "\n",
    "\n",
    "# Eliminar las stopwords de los textos\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "texts = [\n",
    "    \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con una función de pesado específica\n",
    "def train_and_evaluate(vectorizer):\n",
    "    # Vectorizar los textos de entrenamiento y prueba\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Entrenar un clasificador Naive Bayes\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Predecir las etiquetas del conjunto de prueba\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluar el modelo con diferentes funciones de pesado\n",
    "vectorizers = {\n",
    "    \"Count Vectorizer (binary)\": CountVectorizer(binary=True),\n",
    "    \"Count Vectorizer (frequency)\": CountVectorizer(),\n",
    "    \"TF-IDF Vectorizer\": TfidfVectorizer(),\n",
    "}\n",
    "\n",
    "accuracies = {\n",
    "    name: train_and_evaluate(vectorizer) for name, vectorizer in vectorizers.items()\n",
    "}\n",
    "\n",
    "# Imprimir los resultados\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e8b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8275\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Cargar los datos y etiquetas del corpus de movie_reviews\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "\n",
    "# Convertir los documentos en texto y las etiquetas en una lista\n",
    "texts = [\" \".join(doc) for doc, _ in documents]\n",
    "labels = [category for _, category in documents]\n",
    "\n",
    "# Eliminar las stopwords y lematizar los textos\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "texts = [\n",
    "    \" \".join(\n",
    "        [\n",
    "            lemmatizer.lemmatize(word.lower())\n",
    "            for word in text.split()\n",
    "            if word.lower() not in stop_words\n",
    "        ]\n",
    "    )\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorizar los textos utilizando un pesado binario\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar un clasificador Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predecir las etiquetas del conjunto de prueba\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03-representacion-texto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
